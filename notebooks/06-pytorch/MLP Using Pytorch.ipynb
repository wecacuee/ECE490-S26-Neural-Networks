{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98be8324",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71bb1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch as t\n",
    "    import torch.nn as tnn\n",
    "except ImportError:\n",
    "    print(\"Colab users: pytorch comes preinstalled. Select Change Runtime > T4 GPU\")\n",
    "    print(\"Local users: Please install pytorch for your hardware using instructions from here: https://pytorch.org/get-started/locally/\")\n",
    "    print(\"ACG users: Please follow instructions here: https://vikasdhiman.info/ECE490-Neural-Networks/posts/0000-00-06-acg-slurm-jupyter/\")\n",
    "    \n",
    "    raise\n",
    "\n",
    "if t.cuda.is_available():\n",
    "    DEVICE=\"cuda\"\n",
    "elif t.mps.is_available():\n",
    "    DEVICE=\"mps\"\n",
    "else:\n",
    "    DEVICE=\"cpu\"\n",
    "    \n",
    "DTYPE = t.get_default_dtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14e01b-7847-4f44-bb90-68d54b6ac269",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd5fea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doing it the Pytorch way without using our custom feature extraction\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#torch.manual_seed(17) # Only use during debugging\n",
    "\n",
    "# Getting the dataset, the Pytorch way\n",
    "all_training_data = torchvision.datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd6790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = torch.utils.data.random_split(all_training_data, [0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0cd245-cbfc-45d2-aeac-8a705b5020e5",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd30dac-36b8-4cae-8080-adf375d51060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "learning_rate = 1e-3 # controls how fast the \n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29441084-bacd-42a8-a32f-a0c28861c5a0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2e3d62-c39e-46a1-92b5-b5073f40bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_data, shuffle=True, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_data,  batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data,  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a165243f-322d-4af8-8925-bd341abdcdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Define model = ?\n",
    "class MLPNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=10, nclasses=10, input_size=28*28):\n",
    "        super().__init__()\n",
    "        self._layers = torch.nn.ModuleList([torch.nn.Flatten(),\n",
    "            tnn.Linear(input_size, hidden_size),\n",
    "            tnn.ReLU(),\n",
    "            tnn.Linear(hidden_size, nclasses)])\n",
    "    def forward(self, x):\n",
    "        for l in self._layers:\n",
    "            xnext = l(x) # call the layers in sequence\n",
    "            x = xnext\n",
    "        return x\n",
    "model = MLPNetwork()\n",
    "\n",
    "# alternatively you can also\n",
    "# hidden_size=10\n",
    "# nclasses=10\n",
    "# input_size=28*28\n",
    "# model = torch.nn.Sequential(torch.nn.Flatten(),\n",
    "#            tnn.Linear(input_size, hidden_size),\n",
    "#            tnn.ReLU(),\n",
    "#            tnn.Linear(hidden_size, nclasses))\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de86d97-6e73-4ee1-88ea-0232adfb7789",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e35b4ea4-fb12-4f38-bffb-aa4ad87f92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcbae6-9163-4429-b6b2-dbf33c0a17da",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "# Define learning_rate scheduler\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "\n",
    "def loss_and_accuracy(model, loss, validation_dataloader, device=DEVICE):\n",
    "    # Validation loop\n",
    "    validation_size = len(validation_dataloader.dataset)\n",
    "    num_batches = len(validation_dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in validation_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss(pred, y).item()\n",
    "            correct += (pred.argmax(dim=-1) == y).type(DTYPE).sum().item()\n",
    "    model.train()\n",
    "    test_loss /= num_batches\n",
    "    correct /= validation_size\n",
    "    return test_loss, correct\n",
    "    \n",
    "def train(model, loss, training_dataloader, validation_dataloader, device=DEVICE):\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    model.train()\n",
    "    for t in range(epochs):\n",
    "        # Train loop\n",
    "        training_size = len(training_dataloader.dataset)\n",
    "        for batch, (X, y) in enumerate(training_dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss_t = loss(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss_t.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        valid_loss, correct = loss_and_accuracy(model, loss, validation_dataloader, device=device)\n",
    "        #scheduler.step(valid_loss) \n",
    "        valid_losses.append(valid_loss)\n",
    "    \n",
    "        loss_t = loss_t.item()\n",
    "        print(f\"loss: {loss_t:>7f}\", end=\"\\r\")\n",
    "        train_losses.append(loss_t)\n",
    "        \n",
    "        print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\")\n",
    "    return model, train_losses, valid_losses\n",
    "        \n",
    "trained_model, train_losses, valid_losses = train(model, loss, training_dataloader, validation_dataloader)\n",
    "\n",
    "test_loss, correct = loss_and_accuracy(model, loss, test_dataloader)\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9aaa20-4ed3-410d-a7ea-69aabb18e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, 'r', label='train')\n",
    "plt.plot(valid_losses, 'b', label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5535b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = next(iter(test_dataloader))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99748f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The predicted image label is \", model(X.to(DEVICE)).argmax(dim=-1)[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117b2c9-4bdb-4559-945c-82f306ce7a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
