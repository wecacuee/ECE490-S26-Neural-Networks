{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4584a7b8-4616-4a1c-8eaf-89b55b405b85",
   "metadata": {},
   "source": [
    "# CNN: Convolutional Neural Network\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/wecacuee/ECE490-S26-Neural-Networks/blob/master/notebooks/012-example-llm/03-CNN.ipynb\"><strong>OPEN IN COLAB</strong></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceee2b97-baca-4c1c-a610-cc55c867ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab users: pytorch comes preinstalled. Select Change Ru\n",
      "Local users: Please install pytorch for your hardware using instructions from here: https://pytorch.org/get-started/locally/\n",
      "ACG users: Please follow instructions here: https://vikasdhiman.info/ECE490-Neural-Networks/posts/0000-00-06-acg-slurm-jupyter/\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1197841/3538008028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adapted from: Chapter 7 and 8 of Deep Learning with Pytorch by Eli Stevens (2020)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Adapted from: Chapter 7 and 8 of Deep Learning with Pytorch by Eli Stevens (2020)\n",
    "try:\n",
    "    import torch as t\n",
    "    import torch.nn as tnn\n",
    "except ImportError:\n",
    "    print(\"Colab users: pytorch comes preinstalled. Select Change Ru\")\n",
    "    print(\"Local users: Please install pytorch for your hardware using instructions from here: https://pytorch.org/get-started/locally/\")\n",
    "    print(\"ACG users: Please follow instructions here: https://vikasdhiman.info/ECE490-Neural-Networks/posts/0000-00-06-acg-slurm-jupyter/\")\n",
    "    \n",
    "    raise\n",
    "\n",
    "if t.cuda.is_available():\n",
    "    DEVICE=\"cuda\"\n",
    "elif t.mps.is_available():\n",
    "    DEVICE=\"mps\"\n",
    "else:\n",
    "    DEVICE=\"cpu\"\n",
    "    \n",
    "DTYPE = t.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace3403-f93b-4ab8-a715-514d9d552163",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doing it the Pytorch way without using our custom feature extraction\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "torch.manual_seed(17)\n",
    "DATASET_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "DATASET_STD = [0.2470, 0.2435, 0.2616]\n",
    "# Getting the dataset, the Pytorch way\n",
    "all_training_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=Compose([ToTensor(),\n",
    "                       Normalize(DATASET_MEAN, # dataset mean\n",
    "                                 DATASET_STD)]) # dataset std\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=Compose([ToTensor(),\n",
    "                       Normalize(DATASET_MEAN, # dataset mean\n",
    "                                 DATASET_STD)]) # dataset std\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3a7bb-e450-4206-b7ac-b6db1d81b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = torch.utils.data.random_split(all_training_data, [0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615ce36-d305-41c9-b093-5ce9d5953b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = all_training_data[99]\n",
    "img.shape, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c54f6-5d1b-4e43-b042-4caadf4cb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e5d60-2dce-4584-beb7-b81d360dfd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((img.permute(1, 2, 0) *  torch.Tensor(DATASET_STD)\n",
    "            +  torch.Tensor(DATASET_MEAN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515b5e5-1bb2-469c-93e4-ce74d0a858d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in all_training_data], dim=3)\n",
    "imgs.reshape(3, -1).mean(dim=-1), imgs.reshape(3, -1).std(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92268110-8bc4-4dc6-9eb8-d5624b36a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cifar_meta = pickle.load(open(\"data/cifar-10-batches-py/batches.meta\", \"rb\"), encoding='bytes')\n",
    "class_names = [c.decode('utf-8') for c in cifar_meta[b'label_names']]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51792a06-6cdb-4a74-86b7-10e46d3218ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "learning_rate = 1e-3 # controls how fast the gradient descent goes\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "momentum = 0.9\n",
    "\n",
    "training_dataloader = DataLoader(training_data, shuffle=True, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_data,  batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data,  batch_size=batch_size)\n",
    "X, y = next(iter(training_dataloader))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619d6cf-16c9-48c4-9184-ee259f5c4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "# TODO:\n",
    "# Define model = ?\n",
    "\n",
    "model = tnn.Sequential(\n",
    "    tnn.Flatten(),\n",
    "    tnn.Linear(3*32*32, 100),\n",
    "    tnn.ReLU(),\n",
    "    tnn.Linear(100, 10))\n",
    "\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "def loss_and_accuracy(model, loss, validation_dataloader, device=DEVICE):\n",
    "        # Validation loop\n",
    "        validation_size = len(validation_dataloader.dataset)\n",
    "        num_batches = len(validation_dataloader)\n",
    "        test_loss, correct = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval() # Put model in eval mode, affects layers like dropout and batchnorm\n",
    "            for X, y in validation_dataloader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss(pred, y)\n",
    "                correct += (pred.argmax(dim=-1) == y).type(DTYPE).sum()\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        correct /= validation_size\n",
    "        return test_loss, correct\n",
    "    \n",
    "def train(model, loss, training_dataloader, validation_dataloader, device=DEVICE, chkpt_name='model_ckpt.pt', ignore_chkpt=False):\n",
    "    model.to(device)\n",
    "    t0 = 0\n",
    "    if not ignore_chkpt and os.path.exists(f\"runs/{chkpt_name}\"):\n",
    "        checkpoint = torch.load(f\"runs/{chkpt_name}\")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        t0 = checkpoint['epoch']\n",
    "    training_loss_list =  []\n",
    "    valid_loss_list = []\n",
    "    valid_accuracy_list = []\n",
    "    for t in range(t0, epochs):\n",
    "        # Train loop\n",
    "        training_size = len(training_dataloader.dataset)\n",
    "        nbatches = len(training_dataloader)\n",
    "        model.train() # Put model in train mode, affects layers like dropout and batchnorm\n",
    "        for batch, (X, y) in enumerate(training_dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss_t = loss(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss_t.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                #writer.add_scalar(\"Train/loss_batch\", loss_t,  t*nbatches + batch)\n",
    "                loss_t, current = loss_t.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss_t:>7f}  [{current:>5d}/{training_size:>5d}]\", end=\"\\r\")\n",
    "                \n",
    "        training_loss_list.append(loss_t)\n",
    "        valid_loss, correct = loss_and_accuracy(model, loss, validation_dataloader, device=device)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_accuracy_list.append(correct)\n",
    "        print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\")\n",
    "        if t % 3 == 0:\n",
    "            os.makedirs(\"runs\", exist_ok=True)\n",
    "            torch.save({\n",
    "                'epoch': t,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, f\"runs/{chkpt_name}\")\n",
    "    return model\n",
    "        \n",
    "trained_model = train(model, loss, training_dataloader, validation_dataloader, chkpt_name='linear_model_chkpt.pt')\n",
    "\n",
    "test_loss, correct = loss_and_accuracy(model, loss, test_dataloader)\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff932bb0-5bc7-4f75-bd98-83e9ebbaf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model = tnn.Sequential(\n",
    "    tnn.Conv2d(3, 16, 3, padding=1),\n",
    "    tnn.ReLU(),\n",
    "    tnn.MaxPool2d(2),\n",
    "    tnn.Conv2d(16, 16, 3, padding=1),\n",
    "    tnn.ReLU(),\n",
    "    tnn.MaxPool2d(2),\n",
    "    tnn.Flatten(),\n",
    "    tnn.Linear(16*8*8, 100),\n",
    "    tnn.ReLU(),\n",
    "    tnn.Linear(100, 10))\n",
    "\n",
    "trained_model = train(model, loss, training_dataloader, validation_dataloader, \n",
    "                     chkpt_name='conv_model_chkpt.pt', ignore_chkpt=True)\n",
    "\n",
    "test_loss, correct = loss_and_accuracy(model, loss, test_dataloader)\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03fd03-e8b8-41df-8d36-46f033111050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
