{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42018015-919e-444d-89b1-6176eb0d5a7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "  math:\n",
    "    '\\calA': '{\\cal A}'\n",
    "    '\\calB': '{\\cal B}'\n",
    "    '\\calC': '{\\cal C}'\n",
    "    '\\calD': '{\\cal D}'\n",
    "    '\\calE': '{\\cal E}'\n",
    "    '\\calF': '{\\cal F}'\n",
    "    '\\calG': '{\\cal G}'\n",
    "    '\\calH': '{\\cal H}'\n",
    "    '\\calI': '{\\cal I}'\n",
    "    '\\calJ': '{\\cal J}'\n",
    "    '\\calK': '{\\cal K}'\n",
    "    '\\calL': '{\\cal L}'\n",
    "    '\\calM': '{\\cal M}'\n",
    "    '\\calN': '{\\cal N}'\n",
    "    '\\calO': '{\\cal O}'\n",
    "    '\\calP': '{\\cal P}'\n",
    "    '\\calQ': '{\\cal Q}'\n",
    "    '\\calR': '{\\cal R}'\n",
    "    '\\calS': '{\\cal S}'\n",
    "    '\\calT': '{\\cal T}'\n",
    "    '\\calU': '{\\cal U}'\n",
    "    '\\calV': '{\\cal V}'\n",
    "    '\\calW': '{\\cal W}'\n",
    "    '\\calX': '{\\cal X}'\n",
    "    '\\calY': '{\\cal Y}'\n",
    "    '\\calZ': '{\\cal Z}'\n",
    "    '\\setA': '\\textsf{A}'\n",
    "    '\\setB': '\\textsf{B}'\n",
    "    '\\setC': '\\textsf{C}'\n",
    "    '\\setD': '\\textsf{D}'\n",
    "    '\\setE': '\\textsf{E}'\n",
    "    '\\setF': '\\textsf{F}'\n",
    "    '\\setG': '\\textsf{G}'\n",
    "    '\\setH': '\\textsf{H}'\n",
    "    '\\setI': '\\textsf{I}'\n",
    "    '\\setJ': '\\textsf{J}'\n",
    "    '\\setK': '\\textsf{K}'\n",
    "    '\\setL': '\\textsf{L}'\n",
    "    '\\setM': '\\textsf{M}'\n",
    "    '\\setN': '\\textsf{N}'\n",
    "    '\\setO': '\\textsf{O}'\n",
    "    '\\setP': '\\textsf{P}'\n",
    "    '\\setQ': '\\textsf{Q}'\n",
    "    '\\setR': '\\textsf{R}'\n",
    "    '\\setS': '\\textsf{S}'\n",
    "    '\\setT': '\\textsf{T}'\n",
    "    '\\setU': '\\textsf{U}'\n",
    "    '\\setV': '\\textsf{V}'\n",
    "    '\\setW': '\\textsf{W}'\n",
    "    '\\setX': '\\textsf{X}'\n",
    "    '\\setY': '\\textsf{Y}'\n",
    "    '\\setZ': '\\textsf{Z}'\n",
    "    '\\bfa': '\\mathbf{a}'\n",
    "    '\\bfb': '\\mathbf{b}'\n",
    "    '\\bfc': '\\mathbf{c}'\n",
    "    '\\bfd': '\\mathbf{d}'\n",
    "    '\\bfe': '\\mathbf{e}'\n",
    "    '\\bff': '\\mathbf{f}'\n",
    "    '\\bfg': '\\mathbf{g}'\n",
    "    '\\bfh': '\\mathbf{h}'\n",
    "    '\\bfi': '\\mathbf{i}'\n",
    "    '\\bfj': '\\mathbf{j}'\n",
    "    '\\bfk': '\\mathbf{k}'\n",
    "    '\\bfl': '\\mathbf{l}'\n",
    "    '\\bfm': '\\mathbf{m}'\n",
    "    '\\bfn': '\\mathbf{n}'\n",
    "    '\\bfo': '\\mathbf{o}'\n",
    "    '\\bfp': '\\mathbf{p}'\n",
    "    '\\bfq': '\\mathbf{q}'\n",
    "    '\\bfr': '\\mathbf{r}'\n",
    "    '\\bfs': '\\mathbf{s}'\n",
    "    '\\bft': '\\mathbf{t}'\n",
    "    '\\bfu': '\\mathbf{u}'\n",
    "    '\\bfv': '\\mathbf{v}'\n",
    "    '\\bfw': '\\mathbf{w}'\n",
    "    '\\bfx': '\\mathbf{x}'\n",
    "    '\\bfy': '\\mathbf{y}'\n",
    "    '\\bfz': '\\mathbf{z}'\n",
    "    '\\bfalpha': '\\boldsymbol{\\alpha}'\n",
    "    '\\bfbeta': '\\boldsymbol{\\beta}'\n",
    "    '\\bfgamma': '\\boldsymbol{\\gamma}'\n",
    "    '\\bfdelta': '\\boldsymbol{\\delta}'\n",
    "    '\\bfepsilon': '\\boldsymbol{\\epsilon}'\n",
    "    '\\bfzeta': '\\boldsymbol{\\zeta}'\n",
    "    '\\bfeta': '\\boldsymbol{\\eta}'\n",
    "    '\\bftheta': '\\boldsymbol{\\theta}'\n",
    "    '\\bfiota': '\\boldsymbol{\\iota}'\n",
    "    '\\bfkappa': '\\boldsymbol{\\kappa}'\n",
    "    '\\bflambda': '\\boldsymbol{\\lambda}'\n",
    "    '\\bfmu': '\\boldsymbol{\\mu}'\n",
    "    '\\bfnu': '\\boldsymbol{\\nu}'\n",
    "    '\\bfomicron': '\\boldsymbol{\\omicron}'\n",
    "    '\\bfpi': '\\boldsymbol{\\pi}'\n",
    "    '\\bfrho': '\\boldsymbol{\\rho}'\n",
    "    '\\bfsigma': '\\boldsymbol{\\sigma}'\n",
    "    '\\bftau': '\\boldsymbol{\\tau}'\n",
    "    '\\bfupsilon': '\\boldsymbol{\\upsilon}'\n",
    "    '\\bfphi': '\\boldsymbol{\\phi}'\n",
    "    '\\bfchi': '\\boldsymbol{\\chi}'\n",
    "    '\\bfpsi': '\\boldsymbol{\\psi}'\n",
    "    '\\bfomega': '\\boldsymbol{\\omega}'\n",
    "    '\\bfxi': '\\boldsymbol{\\xi}'\n",
    "    '\\bfell': '\\boldsymbol{\\ell}'\n",
    "    '\\bfA': '\\mathbf{A}'\n",
    "    '\\bfB': '\\mathbf{B}'\n",
    "    '\\bfC': '\\mathbf{C}'\n",
    "    '\\bfD': '\\mathbf{D}'\n",
    "    '\\bfE': '\\mathbf{E}'\n",
    "    '\\bfF': '\\mathbf{F}'\n",
    "    '\\bfG': '\\mathbf{G}'\n",
    "    '\\bfH': '\\mathbf{H}'\n",
    "    '\\bfI': '\\mathbf{I}'\n",
    "    '\\bfJ': '\\mathbf{J}'\n",
    "    '\\bfK': '\\mathbf{K}'\n",
    "    '\\bfL': '\\mathbf{L}'\n",
    "    '\\bfM': '\\mathbf{M}'\n",
    "    '\\bfN': '\\mathbf{N}'\n",
    "    '\\bfO': '\\mathbf{O}'\n",
    "    '\\bfP': '\\mathbf{P}'\n",
    "    '\\bfQ': '\\mathbf{Q}'\n",
    "    '\\bfR': '\\mathbf{R}'\n",
    "    '\\bfS': '\\mathbf{S}'\n",
    "    '\\bfT': '\\mathbf{T}'\n",
    "    '\\bfU': '\\mathbf{U}'\n",
    "    '\\bfV': '\\mathbf{V}'\n",
    "    '\\bfW': '\\mathbf{W}'\n",
    "    '\\bfX': '\\mathbf{X}'\n",
    "    '\\bfY': '\\mathbf{Y}'\n",
    "    '\\bfZ': '\\mathbf{Z}'\n",
    "    '\\bfGamma': '\\boldsymbol{\\Gamma}'\n",
    "    '\\bfDelta': '\\boldsymbol{\\Delta}'\n",
    "    '\\bfTheta': '\\boldsymbol{\\Theta}'\n",
    "    '\\bfLambda': '\\boldsymbol{\\Lambda}'\n",
    "    '\\bfPi': '\\boldsymbol{\\Pi}'\n",
    "    '\\bfSigma': '\\boldsymbol{\\Sigma}'\n",
    "    '\\bfUpsilon': '\\boldsymbol{\\Upsilon}'\n",
    "    '\\bfPhi': '\\boldsymbol{\\Phi}'\n",
    "    '\\bfPsi': '\\boldsymbol{\\Psi}'\n",
    "    '\\bfOmega': '\\boldsymbol{\\Omega}'\n",
    "    '\\bbA': '\\mathbb{A}'\n",
    "    '\\bbB': '\\mathbb{B}'\n",
    "    '\\bbC': '\\mathbb{C}'\n",
    "    '\\bbD': '\\mathbb{D}'\n",
    "    '\\bbE': '\\mathbb{E}'\n",
    "    '\\bbF': '\\mathbb{F}'\n",
    "    '\\bbG': '\\mathbb{G}'\n",
    "    '\\bbH': '\\mathbb{H}'\n",
    "    '\\bbI': '\\mathbb{I}'\n",
    "    '\\bbJ': '\\mathbb{J}'\n",
    "    '\\bbK': '\\mathbb{K}'\n",
    "    '\\bbL': '\\mathbb{L}'\n",
    "    '\\bbM': '\\mathbb{M}'\n",
    "    '\\bbN': '\\mathbb{N}'\n",
    "    '\\bbO': '\\mathbb{O}'\n",
    "    '\\bbP': '\\mathbb{P}'\n",
    "    '\\bbQ': '\\mathbb{Q}'\n",
    "    '\\bbR': '\\mathbb{R}'\n",
    "    '\\bbS': '\\mathbb{S}'\n",
    "    '\\bbT': '\\mathbb{T}'\n",
    "    '\\bbU': '\\mathbb{U}'\n",
    "    '\\bbV': '\\mathbb{V}'\n",
    "    '\\bbW': '\\mathbb{W}'\n",
    "    '\\bbX': '\\mathbb{X}'\n",
    "    '\\bbY': '\\mathbb{Y}'\n",
    "    '\\bbZ': '\\mathbb{Z}'\n",
    "    '\\p'  : '\\partial'\n",
    "    '\\proj': '\\mbox{proj}'\n",
    "    '\\bbfX': '\\bar{\\bfX}'\n",
    "    '\\Diag': '\\mbox{Diag}'\n",
    "    '\\sign': '\\mbox{sign}'\n",
    "    '\\bfone': '\\mathbf{1}'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f0de9-6a87-4e9f-99dc-4317d543b3d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Practice problems for Midterm 1 ECE 490/590 Spring 2025\n",
    "\n",
    "#### Date: Oct 9, 2025\n",
    "#### Instructor: Vikas Dhiman (vikas.dhiman@maine.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f65ed8-5a17-4984-abd8-46886ad6b499",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "1. Total marks are 75.\n",
    "2. Total time allowed is 75 min.\n",
    "3. One page 8\"x11\" cheatsheet is allowed.\n",
    "4. Calculators are allowed.\n",
    "5. Computers are not allowed. You must know approximately know what the Python code will output. Minor formatting errors will not be penalized.\n",
    "\n",
    "<style>\n",
    "@media print {\n",
    "    .pagebreak { page-break-before: always; } /* page-break-after works, as well */\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0604d8-4284-4703-9b9c-c240ddbd5c52",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### 1. Write your name here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe27db05-711f-4e27-8938-bac01baee281",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### 2. Write your email here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f648db-015b-4bbe-8b0f-376ed2a78d42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Python Basics\n",
    "\n",
    "The midterm will be on paper, no computers will be allowed. Make sure you know what the python code output should be.\n",
    "\n",
    "Python questions will be restriced to content covered in Python_1.ipynb,  Python_2.ipynb, Python_3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d559973",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Python Basics\n",
    "\n",
    "The midterm will be on paper, no computers will be allowed. Make sure you know what the python code output should be.\n",
    "\n",
    "Python questions will be restriced to content covered in Python_1.ipynb,  Python_2.ipynb, NumpyTutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8525873-b1ad-4be1-94d1-606095e85df0",
   "metadata": {},
   "source": [
    "##### Q1. What will the following code print?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ae58c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello' \"ECE\". pi is 3.142\n"
     ]
    }
   ],
   "source": [
    "hello = \"'Hello'\"\n",
    "name = '\"ECE\"'\n",
    "pi = 3.1419\n",
    "print(f'{hello:s} {name}. pi is {pi:.03f}')  # string formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a4622-b2b2-419c-a603-d41cd3003119",
   "metadata": {},
   "source": [
    "##### Q2. What will the following code print?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1905200-14e2-4f55-a04b-cd296dd4ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "xs = [1, 2, 3, 'hello', [4, 5, 6]]    # Create a list\n",
    "print(xs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e178701-325e-4e3a-ba20-a03403cd3134",
   "metadata": {},
   "source": [
    "##### Q3. What will the following code print?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682f2ecd-cf1c-4b69-948e-772b2d8511da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "nums = list(range(5))    # range is a built-in function that creates a list of integers\n",
    "print(nums[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f98fa-ba06-4d9b-b7b8-93e676175036",
   "metadata": {},
   "source": [
    "##### Q4. Which code is faster for very large lists and dictionaries ? Option 1 or Option 2? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419ef45b-3085-4a5d-82d9-05f1b517a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furry\n",
      "furry\n"
     ]
    }
   ],
   "source": [
    "# Code Option 1:\n",
    "d = {'cat': 'cute', 'dog': 'furry'}  # Create a new dictionary with some data\n",
    "print(d['dog'])\n",
    "# Code option 2:\n",
    "keys = ['cat', 'dog'] # Create the dictionary with keys as lists\n",
    "values = ['cute', 'furry'] # # Create the dictionary with values as lists\n",
    "print(values[keys.index('dog')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e2535-e051-4582-aef6-b6521259aa84",
   "metadata": {},
   "source": [
    "##### Q5. Which code is faster for very large lists and dictionaries ? Option 1 or Option 2? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d166522-961f-40f5-aed3-699fad4938bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furry\n",
      "furry\n"
     ]
    }
   ],
   "source": [
    "# Code Option 1:\n",
    "d = {0: 'cute', 1: 'furry'}  # Create a new dictionary with some data\n",
    "print(d[1])\n",
    "# Code option 2:\n",
    "values = ['cute', 'furry'] # # Create the dictionary with values as lists\n",
    "print(values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003dba8-090c-443c-8639-597a8c0f97b2",
   "metadata": {},
   "source": [
    "##### Q6. What is the output of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86765df1-5e0f-424d-98e6-9629892823f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "class Value:\n",
    "    def __init__(self, v):\n",
    "        self.v = v\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return self.v * other\n",
    "\n",
    "print(Value(3) + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ac162-6e58-43fe-86b0-7bee84f07fdd",
   "metadata": {},
   "source": [
    "## Numpy basics\n",
    "\n",
    "Python questions will be restriced to content covered in NumpyTutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5df094-3c63-4754-aaae-a0c01975145f",
   "metadata": {},
   "source": [
    "##### Q7: What is the output of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6c0649-167a-4956-9720-0d3e0dc867e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "y = np.array([[5, 6]])\n",
    "np.concatenate((x.T, y.T), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb596d3-9422-4328-948a-f885eddcec8a",
   "metadata": {},
   "source": [
    "##### Q8. What is the output of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2daf1b89-bf3f-479c-b563-a0c6de7bee65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17],\n",
       "       [39]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4]])\n",
    "y = np.array([[5, 6]])\n",
    "x @ y.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331dfd8f-cdff-498c-b0f3-ba1bd2c9d154",
   "metadata": {},
   "source": [
    "##### Q9. What is the output of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0290d466-04a4-4b4c-9ac9-f19ca047cb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 39])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4]])\n",
    "y = np.array([[5, 6]])\n",
    "(x * y).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f6fc16-3de4-4ac8-86e6-03a3088d8ba6",
   "metadata": {},
   "source": [
    "## Linear algebra and it's geometry\n",
    "\n",
    "##### Q10. \n",
    "Show that for any vector $\\bfa = [a_1, a_2, \\dots, a_n]$, it's magnitude squared is same as dot product with itself i.e. $\\|\\bfa\\|^2 = \\bfa^\\top \\bfa$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e621ade3-bd54-4772-b53c-87a23695c6bb",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-088f9689ec190305",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "A10. The mangitude of n-D vector is given by $\\|\\bfa\\| = \\sqrt{a_1^2 + a_2^2 + \\dots + a_n^2}$ and dot product the vector with itself is given by\n",
    "$\\bfa^\\top \\bfa = a_1 a_1 + a_2 a_2 + \\dots + a_n a_n = a_1^2 + a_2^2 + \\dots + a_n^2$. Squaring the magnitude gives us $\\|\\bfa\\|^2 = a_1^2 + a_2^2 + \\dots + a_n^2$, which is same as $\\bfa^\\top \\bfa$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e595223-7248-42d6-8b8b-dbd40803d2a6",
   "metadata": {},
   "source": [
    "\n",
    "Q11. For given vectors $\\bfv$ and $\\bfu$ find the projection of $\\bfv$ on $\\bfu$ $\\proj_\\bfu \\bfv$. Also find the equation of dotted line which is perpendicular to $\\bfu$ and passes through $\\bfv$. Convert the equation of line to the form $y = m x + c$.\n",
    "\n",
    "$\\bfv = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix} $ and $\\bfu = \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix}$.\n",
    "\n",
    "![](https://openstax.org/apps/archive/20221219.191545/resources/263b8d95f699470f4cf6d49170b85118906c5ede)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d432dd1-85eb-4208-8c29-14d088063e6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "A11. \n",
    "1. $\\proj_\\bfu \\bfv = \\bfv^\\top \\frac{\\bfu}{\\|\\bfu\\|} = \\frac{12}{\\sqrt{13}}$\n",
    "2. The dotted line is the set of all points $\\bfx \\in \\bbR^2$ that satisfy $\\bfu^\\top \\bfx = \\bfu^\\top \\bfv$ \n",
    "3. Let $\\bfx = [x, y]$. Then the above equation of line can be written as $[3, 2] \\begin{bmatrix} x \\\\ y \\end{bmatrix} = 12$ or $3x + 2y = 12$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887eff0e-b3e5-4be6-a037-bc3f1d87fc0e",
   "metadata": {},
   "source": [
    "\n",
    "##### Q12. \n",
    "Convert the following scalar equation into vector form. Your end result should contain $\\bfm = [m; c]$, $\\bfy = [y_1; y_2; \\dots; y_n]$ and $\\bfx = [x_1; x_2, \\dots, x_n]$. You can define other vectors and matrices as needed, included a vector of ones like $\\mathbb{1}_n$.\n",
    "\n",
    "$$ e(m, c, (x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)) = (y_1 - (x_1 m + c))^2 + (y_2 - (x_2 m + c))^2 + \\dots + (y_n - (x_n m + c))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960b458-dc4c-4a35-81fd-167474e73618",
   "metadata": {
    "tags": []
   },
   "source": [
    "A12. \n",
    "Recall that the magnitude of a vector $ \\|\\bfv\\| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^n}$ has a similar form to the error function. This suggests that we can define an error vector with the signed error for each data point as it's elements\n",
    "\n",
    "$$ \\bfe = \\begin{bmatrix}y_1 - (mx_1 + c)\\\\ y_2 - (mx_2 + c)\\\\ \\vdots \\\\ y_n - (mx_n + c)\\end{bmatrix}$$\n",
    "\n",
    "The total error is same as minimizing the square of error vector magnitude which is further same as vector product with itself.\n",
    "\n",
    "$$  e(m, c, (x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)) = \\|\\bfe\\|^2 = \\bfe^\\top \\bfe$$\n",
    "\n",
    "Let us define $\\bfx = [x_1; \\dots; x_n]$ to denote the vector of all x coordinates of the dataset and $\\bfy = [y_1; \\dots; y_n]$ to denote y coordinates. Then the error vector is:\n",
    "$$ \\bfe = \\bfy - (\\bfx m +  \\mathbf{1}_n c)$$ \n",
    "\n",
    "where $\\mathbf{1}_n$ is a n-D vector of all ones. Finally, we vectorize parameters of the line $\\bfm = [m; c]$. We will also need to horizontally concatenate $\\bfx$ and $\\mathbf{1}_n$. Let's call the result $\\bfX = [\\bfx, \\mathbf{1}_n] \\in \\bbR^{n \\times 2}$. Now, the error vector looks like this:\n",
    "\n",
    "$$ \\bfe = \\bfy - \\bfX \\bfm$$ \n",
    "\n",
    "Expanding the error magnitude:\n",
    "\n",
    "$$ \\|\\bfe\\|^2 = (\\bfy - \\bfX \\bfm)^\\top (\\bfy - \\bfX \\bfm)\n",
    "\\\\\n",
    "= \\bfy^\\top\\bfy + \\bfm^\\top \\bfX^\\top \\bfX \\bfm - 2\\bfy^\\top \\bfX \\bfm \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99590ad4",
   "metadata": {},
   "source": [
    "\n",
    "##### Q13: \n",
    "Convert the following scalar equation into vector form. Your end result should contain $\\bfm = [a; b; c]$, $\\bfz = [z_1; z_2; \\dots; z_n]$, $\\bfy = [y_1; y_2; \\dots; y_n]$ and $\\bfx = [x_1; x_2, \\dots, x_n]$. You can define other vectors and matrices as needed, included a vector of all ones like $\\mathbb{1}_n$.\n",
    "\n",
    "$$ e(a, b, c, (x_1, y_1, z_1), (x_2, y_2, z_2), \\dots, (x_n, y_n, z_n)) = (z_1 - (x_1 a + y_1 b + c))^2 + (z_2 - (x_2 a + y_2 b + c))^2 + \\dots + (z_n - (x_n a + y_n b + c))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0dd55",
   "metadata": {
    "tags": []
   },
   "source": [
    "A13: A variation of A12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89874c8-f201-44e4-a12b-5505c744c4bd",
   "metadata": {},
   "source": [
    "##### Q14\n",
    "\n",
    "Convert the following vector equation into even more vectorized form. \n",
    "\n",
    "$$ e(m_0, \\bfm, (\\bfx_1, y_1), (\\bfx_2, y_2), \\dots, (\\bfx_n, y_n)) = (y_1 - (\\bfx_1^\\top \\bfm + m_0))^2 + (y_2 - (\\bfx_2^\\top \\bfm + m_0))^2 + \\dots + (y_n - (\\bfx_n^\\top \\bfm + m_0))^2$$\n",
    "\n",
    "where $\\bfm = [m_1; m_2; \\dots; m_p] \\in \\bbR^p$ is a p-dimensional vector and $\\bfx_i = [x_{i1}; x_{i2}; \\dots; x_{ip}] \\in \\bbR^p$ are p-dimensional vectors for all $i = \\{1, 2, \\dots n\\}$\n",
    "\n",
    "Your end result should contain $\\bfq = [m_0, m_1, m_2, \\dots, m_p] \\in \\bbR^{p+1}$, $\\bfy = [y_1; y_2; \\dots; y_n]\\in \\bbR^n$ and \n",
    "\n",
    "\\begin{align} \\bfX = \n",
    "\\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p}\\\\\n",
    "x_{21} & x_{22} & \\dots & x_{2p} \\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\ \n",
    "x_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}  = \\begin{bmatrix}\n",
    "\\bfx_1^\\top \\\\\n",
    "\\bfx_2^\\top \\\\\n",
    "\\vdots\\\\\n",
    "\\bfx_n^\\top \\end{bmatrix}\n",
    "\\in \\bbR^{n \\times p}\n",
    "\\end{align}. \n",
    "\n",
    "You can define other vectors and matrices as needed, included a vector of all ones like $\\mathbb{1}_n$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730cbf5e-9b5c-4be9-8dc2-d98a83939c55",
   "metadata": {
    "tags": []
   },
   "source": [
    "A15. \n",
    "\n",
    "Recall that the magnitude of a vector $ \\|\\bfv\\| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^n}$ has a similar form to the error function. This suggests that we can define an error vector with the signed error for each data point as it's elements\n",
    "\n",
    "$$ \\bfe = \\begin{bmatrix}y_1 - (\\bfx_1^\\top\\bfm + m_0)\\\\ y_2 - (\\bfx_2^\\top\\bfm + m_0)\\\\ \\vdots \\\\ y_n - (\\bfx_2^\\top\\bfm_2 + m_0)\\end{bmatrix}$$\n",
    "\n",
    "The total error is same as minimizing the square of error vector magnitude which is further same as vector product with itself.\n",
    "\n",
    "$$  e(m_0, \\bfm, (\\bfx_1, y_1), (\\bfx_2, y_2), \\dots, (\\bfx_n, y_n)) = \\|\\bfe\\|^2 = \\bfe^\\top \\bfe$$\n",
    "\n",
    "Let us define $\\bfX = [\\bfx_1^\\top; \\dots; \\bfx_n^\\top]$ to denote the vector of all x coordinates of the dataset and $\\bfy = [y_1; \\dots; y_n]$ to denote y coordinates. Then the error vector is:\n",
    "$$ \\bfe = \\bfy - (\\mathbf{1}_n m_0 + \\bfX \\bfm)$$ \n",
    "\n",
    "where $\\mathbf{1}_n$ is a n-D vector of all ones. Finally, we call parameters of the line $\\bfq = [m_0; \\bfm]$. We will also need to horizontally concatenate $\\bfX$ and $\\mathbf{1}_n$. Let's call the result $\\bar{\\bfX} = [\\mathbf{1}_n, \\bfX] \\in \\bbR^{n \\times (p+1)}$. Now, the error vector looks like this:\n",
    "\n",
    "$$ \\bfe = \\bfy - \\bar{\\bfX} \\bfq$$ \n",
    "\n",
    "Expanding the error magnitude:\n",
    "$$ \\|\\bfe\\|^2 = (\\bfy - \\bbfX \\bfq)^\\top (\\bfy - \\bbfX \\bfq)\n",
    "\\\\\n",
    "= \\bfy^\\top\\bfy + \\bfq^\\top \\bbfX^\\top \\bbfX \\bfq - 2\\bfy^\\top \\bbfX \\bfq \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d402c",
   "metadata": {},
   "source": [
    "\n",
    "##### Q16: \n",
    "\n",
    "Convert the following scalar equation into vector form. Your end result should contain $\\bfm = [m; c]$, the matrix $\\bfW = \\Diag([w_1; w_2; \\dots; w_n])$, $\\bfy = [y_1; y_2; \\dots; y_n]$ and $\\bfx = [x_1; x_2, \\dots, x_n]$. You can define other vectors and matrices as needed, included a vector of all ones like $\\mathbb{1}_n$.\n",
    "\n",
    "\n",
    "$$ e(m, c, (x_1, y_1, w_1), (x_2, y_2, w_2), \\dots, (x_n, y_n, w_n)) = w_1^2(y_1 - (x_1 m + c))^2 + w_2^2(y_2 - (x_2 m + c))^2 + \\dots + w_n^2(y_n - (x_n m + c))^2$$\n",
    "\n",
    "The matrix $\\bfW$ is defined as $\\Diag([w_1; w_2; \\dots; w_n])$ which indicates that $\\bfW$ is diagonal matrix of $[w_1; w_2; \\dots; w_n]$.\n",
    "\n",
    "$$ \\bfW = \\Diag([w_1; w_2; \\dots; w_n]) = \n",
    "\\begin{bmatrix}w_1 & 0 & \\dots & 0\\\\\n",
    "0 & w_2 & \\dots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\dots & w_n\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fcf21",
   "metadata": {
    "tags": []
   },
   "source": [
    "A16:\n",
    "\n",
    "Recall that the magnitude of a vector $ \\|\\bfv\\| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^n}$ has a similar form to the error function. This suggests that we can define an error vector with the signed error for each data point as it's elements\n",
    "\n",
    "$$ \\bfe = \\begin{bmatrix}y_1 - (mx_1 + c)\\\\ y_2 - (mx_2 + c)\\\\ \\vdots \\\\ y_n - (mx_n + c)\\end{bmatrix}$$\n",
    "and  let $\\bfW = \\Diag([w_1; w_2; \\dots; w_n])$.\n",
    "\n",
    "Note that \n",
    "$$ \\bfW \\bfe = \\begin{bmatrix}w_1(y_1 - (mx_1 + c))\\\\ w_2(y_2 - (mx_2 + c))\\\\ \\vdots \\\\ w_3(y_n - (mx_n + c))\\end{bmatrix}$$\n",
    "\n",
    "The total error is same as the square of error vector magnitude \n",
    "\n",
    "$$ e(m, c, (x_1, y_1, w_1), (x_2, y_2, w_2), \\dots, (x_n, y_n, w_n)) = w_1^2(y_1 - (x_1 m + c))^2 + w_2^2(y_2 - (x_2 m + c))^2 + \\dots + w_n^2(y_n - (x_n m + c))^2 = \\|\\bfW \\bfe\\|^2$$\n",
    "\n",
    "The square of error vector magnitude is same as dot product with itself,\n",
    "$$ \\|\\bfW \\bfe\\|^2 = (\\bfW\\bfe)^\\top(\\bfW\\bfe) = \\bfe^\\top \\bfW^\\top \\bfW \\bfe$$\n",
    "\n",
    "Let us define $\\bfx = [x_1; \\dots; x_n]$ to denote the vector of all x coordinates of the dataset and $\\bfy = [y_1; \\dots; y_n]$ to denote y coordinates. Then the error vector is:\n",
    "$$ \\bfe = \\bfy - (\\bfx m +  \\mathbf{1}_n c)$$ \n",
    "\n",
    "where $\\mathbf{1}_n$ is a n-D vector of all ones. Finally, we vectorize parameters of the line $\\bfm = [m; c]$. We will also need to horizontally concatenate $\\bfx$ and $\\mathbf{1}_n$. Let's call the result $\\bfX = [\\bfx, \\mathbf{1}_n] \\in \\bbR^{n \\times 2}$. Now, the error vector looks like this:\n",
    "\n",
    "$$ \\bfe = \\bfy - \\bfX \\bfm$$ \n",
    "\n",
    "Expanding the error magnitude:\n",
    "\n",
    "$$ \\|\\bfW\\bfe\\|^2 = (\\bfy - \\bfX \\bfm)^\\top \\bfW^\\top\\bfW (\\bfy - \\bfX \\bfm)\n",
    "\\\\\n",
    "= \\bfy^\\top\\bfW^\\top\\bfW\\bfy + \\bfm^\\top \\bfX^\\top \\bfW^\\top\\bfW\\bfX \\bfm - 2\\bfy^\\top \\bfW^\\top\\bfW\\bfX \\bfm \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812bd1c",
   "metadata": {},
   "source": [
    "##### Q17:\n",
    "\n",
    "Using vector derivatives find the minimum of the following vector quadratic function in $\\bfm$:\n",
    "\n",
    "$$\\arg~\\min_{\\bfm} e(\\bfm) = \\bfy^\\top\\bfW^\\top\\bfW\\bfy + \\bfm^\\top \\bfX^\\top \\bfW^\\top\\bfW\\bfX \\bfm - 2\\bfy^\\top \\bfW^\\top\\bfW\\bfX \\bfm $$\n",
    "\n",
    "The dimensions of the each of the variables are given $\\bfm \\in \\bbR^p$, $\\bfy \\in \\bbR^n$, $\\bfW \\in \\bbR^{n \\times n}$, $\\bfX \\in \\bbR^{n \\times p}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e375921-9d87-4cae-afda-af0d2f73b5c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "A17:\n",
    "\\begin{align}\n",
    "\\mathbf{0}^\\top &= \\frac{\\p }{\\p \\bfm} (\\bfy^\\top\\bfW^\\top\\bfW\\bfy + \\bfm^\\top \\bfX^\\top \\bfW^\\top\\bfW\\bfX \\bfm - 2\\bfy^\\top \\bfW^\\top\\bfW\\bfX \\bfm)\\\\\n",
    "      &= 2 {\\bfm^*}^\\top \\bfX^\\top \\bfW^\\top \\bfW \\bfX  - 2\\bfy^\\top \\bfW^\\top \\bfW \\bfX\n",
    "\\end{align}\n",
    "\n",
    "This gives us the solution\n",
    "$$ \\bfm^* = (\\bfX^\\top \\bfW^\\top \\bfW \\bfX)^{-1} \\bfX^\\top \\bfW^\\top \\bfW \\bfy $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3deaf3-5ea3-4312-a50a-56c2b1a64892",
   "metadata": {},
   "source": [
    "## Vector derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30144d4e-eb5a-41c8-91b3-487bc6e8e04a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Q18:\n",
    "\n",
    "Find the derivative of $f(\\bfx) = (\\bfx - \\bfa_1)^\\top A (\\bfx - \\bfa_2)$ with respecto to $\\bfx$.\n",
    "\n",
    "You can assume $A \\in \\bbR^{n\\times n}$ to be symmetric. The size of vectors are $\\bfx, \\bfa_1, \\bfa_2, \\bfa_3, \\bfb \\in \\bbR^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5987e4f0-5f42-45f4-82f5-40e4cc47f1b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "A18\n",
    "\n",
    "$$ f(\\bfx) = (\\bfx - \\bfa_1)^\\top A (\\bfx - \\bfa_2)\\\\\n",
    "= \\bfx^\\top A \\bfx - \\bfa_1^\\top A \\bfx - \\bfx^\\top A \\bfa_2 + \\bfa_1^\\top A\\bfa_2\\\\\n",
    "$$\n",
    "\n",
    "Note that $\\bfx^\\top A \\bfa_2 $ is a scalar. That's why we can replace it with its transpose $\\bfx^\\top A \\bfa_2 = \\bfa_2^\\top A \\bfx$\n",
    "\n",
    "$$\n",
    "= \\bfx^\\top A \\bfx - (\\bfa_1 + \\bfa_2)^\\top A \\bfx + \\bfa_1^\\top A\\bfa_2$$ \n",
    "\n",
    "$$\\frac{\\partial f}{\\partial \\bfx} = 2\\bfx^\\top A - (\\bfa_1 + \\bfa_2)^\\top A\\\\\n",
    "= (2\\bfx - (\\bfa_1 + \\bfa_2))^\\top A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ad915-3ee6-466c-bea7-70830cb5efc1",
   "metadata": {},
   "source": [
    "##### Q19:\n",
    "Find the quadratic approximation of the following function near the point $\\bfx_0$:\n",
    "\n",
    "$$ f(\\bfx) = \\left((\\bfx - \\bfa_1)^\\top A (\\bfx - \\bfa_2)\\right) \\left((\\bfx - \\bfa_3)^\\top \\bfb\\right) $$\n",
    "\n",
    "You can assume $A \\in \\bbR^{n\\times n}$ to be symmetric. The size of vectors are $\\bfx, \\bfa_1, \\bfa_2, \\bfa_3, \\bfb \\in \\bbR^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbb523-797d-4fe2-8de8-713f118970f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "A19:\n",
    "\n",
    "$$ [\\nabla_\\bfx f(\\bfx)]^\\top = \\left((\\bfx - \\bfa_1)^\\top A (\\bfx - \\bfa_2)\\right) \\bfb^\\top+ ((\\bfx - \\bfa_3)^\\top \\bfb)\\left((2\\bfx - (\\bfa_1 + \\bfa_2))^\\top A\\right)$$\n",
    "$$ \\nabla_\\bfx f(\\bfx) = \\left((\\bfx - \\bfa_1)^\\top A (\\bfx - \\bfa_2)\\right) \\bfb + ((\\bfx - \\bfa_3)^\\top \\bfb)\\left(A (2\\bfx - (\\bfa_1 + \\bfa_2))\\right) $$\n",
    "\n",
    "$$ \\nabla_\\bfx f(\\bfx_0) = \\left((\\bfx_0 - \\bfa_1)^\\top A (\\bfx_0 - \\bfa_2)\\right) \\bfb + ((\\bfx_0 - \\bfa_3)^\\top \\bfb)\\left(A (2\\bfx_0 - (\\bfa_1 + \\bfa_2))\\right) $$\n",
    "\n",
    "$$ H f(\\bfx) = \\nabla^2_\\bfx f(\\bfx) =  \\bfb (2\\bfx - (\\bfa_1 + \\bfa_2))^\\top A \n",
    "+ \\left(A (2\\bfx - (\\bfa_1 + \\bfa_2))\\right)\\bfb^\\top \n",
    "+ \\left((\\bfx - \\bfa_3)^\\top \\bfb\\right)(2A) $$\n",
    "\n",
    "$$ H f(\\bfx_0) = \\nabla^2_\\bfx f(\\bfx_0) =  \\bfb (2\\bfx_0 - (\\bfa_1 + \\bfa_2))^\\top A \n",
    "+ \\left(A (2\\bfx_0 - (\\bfa_1 + \\bfa_2))\\right)\\bfb^\\top \n",
    "+ \\left((\\bfx_0 - \\bfa_3)^\\top \\bfb\\right)(2A) $$\n",
    "\n",
    "The quadratic approximation by Taylor series is:\n",
    "$$ f(\\bfx) = f(\\bfx_0) + [\\nabla_\\bfx f(\\bfx_0)]^\\top (\\bfx - \\bfx_0) + (\\bfx - \\bfx_0)^\\top H f(\\bfx_0) (\\bfx - \\bfx_0) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c0173-7114-4d07-b6e3-ec31577428d7",
   "metadata": {},
   "source": [
    "##### Q20\n",
    "\n",
    "Show that for $\\bfc, \\bfx \\in \\bbR^n$\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\p }{ \\p \\bfx} \\bfc^\\top \\bfx = \\bfc^\\top\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080da5bb-e446-4211-a497-cd8d9dbe28d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "A20:\n",
    "Let $\\bfc = [c_1, c_2, \\dots, c_n]$ and $\\bfx = [x_1, x_2, \\dots x_n]$\n",
    "\n",
    "Let $f(\\bfx) = \\bfc^\\top \\bfx = c_1 x_1 + c_2 x_2 + \\dots c_n x_n$\n",
    "\n",
    "$$\\frac{\\p f}{\\p x_1} = c_1\\\\\n",
    "\\frac{\\p f}{\\p x_2} = c_2\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\p f}{\\p x_n} = c_n\\\\\n",
    "$$\n",
    "By Jacobian convention, we arrange the partial derivatives in a row vector:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\p }{ \\p \\bfx} \\bfc^\\top \\bfx = \n",
    "\\begin{bmatrix} \\frac{\\p f}{\\p x_1} & \\frac{\\p f}{\\p x_2} & \\dots & \\frac{\\p f}{\\p x_n}\\end{bmatrix}\n",
    "\\\\\n",
    "= \\begin{bmatrix} c_1 & c_2 & \\dots & c_n\\end{bmatrix} = \\bfc^\\top \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d0816-731b-4bca-a070-2f734cb2dcf4",
   "metadata": {},
   "source": [
    "##### Q21:\n",
    "\n",
    "Show that for $\\bfA \\in \\bbR^{n \\times n}$, $\\bfx \\in \\bbR^n$\n",
    "\\begin{align}\n",
    "\\frac{\\p }{ \\p \\bfx} \\bfA \\bfx = \\bfA\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff75c1e-b2b7-4dcc-8f84-73c44b9f9404",
   "metadata": {
    "tags": []
   },
   "source": [
    "A21:\n",
    "Let $\\bfx = [x_1; x_2; \\dots x_n]$\n",
    "\n",
    "Let $\\bfA = \\begin{bmatrix} a_{11} & a_{12}  & \\dots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\dots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{n1} & a_{n2} & \\dots & a_{nn} \\end{bmatrix} \n",
    "= \\begin{bmatrix} \\bfa_1^\\top \\\\ \\bfa_2^\\top \\\\ \\vdots \\\\ \\bfa_n^\\top \\end{bmatrix}$,\n",
    "where $\\bfa_i^\\top  \\in \\bbR^{1 \\times n}$ are the row vectors of  matrix $\\bfA$.\n",
    "\n",
    "Then $$ \\bfA \\bfx = \\begin{bmatrix} \\bfa_1^\\top \\\\ \\bfa_2^\\top \\\\ \\vdots \\\\ \\bfa_n^\\top \\end{bmatrix}\\bfx \n",
    "= \\begin{bmatrix} \\bfa_1^\\top \\bfx \\\\ \\bfa_2^\\top \\bfx \\\\ \\vdots \\\\ \\bfa_n^\\top\\bfx  \\end{bmatrix} $$\n",
    "\n",
    "Let \n",
    "$$\\bff(\\bfx) = \n",
    "\\begin{bmatrix} f_1(\\bfx) \\\\ f_2(\\bfx) \\\\ \\vdots\\\\ f_n(\\bfx) \\end{bmatrix}\n",
    "= \\bfA \\bfx = \\begin{bmatrix} \\bfa_1^\\top \\bfx \\\\ \\bfa_2^\\top \\bfx \\\\ \\vdots \\\\ \\bfa_n^\\top\\bfx  \\end{bmatrix}$$\n",
    "\n",
    "By Jacobian convention we arrange the partial derivatives of each function component column-wise\n",
    "\n",
    "$$ \\frac{\\p \\bff(\\bfx)}{\\p \\bfx} = \n",
    "\\begin{bmatrix} \\frac{\\p f_1(\\bfx)}{\\p \\bfx} \\\\\n",
    "\\frac{\\p f_2(\\bfx)}{\\p \\bfx} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\p f_n(\\bfx)}{\\p \\bfx} \\end{bmatrix} \n",
    "= \\begin{bmatrix} \\frac{\\p \\bfa_1^\\top \\bfx}{\\p \\bfx} \\\\\n",
    "\\frac{\\p \\bfa_2^\\top \\bfx}{\\p \\bfx} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\p \\bfa_2^\\top \\bfx}{\\p \\bfx} \\end{bmatrix} \n",
    "= \\begin{bmatrix} \\bfa_1^\\top \\\\ \\bfa_2^\\top \\\\ \\vdots \\\\ \\bfa_n^\\top \\end{bmatrix}\n",
    "= \\bfA\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae15c5c9-3982-46a4-bd98-1cdeb623d8e8",
   "metadata": {},
   "source": [
    "##### Q22:\n",
    "\n",
    "Use vector-derivative chain rule:\n",
    "\n",
    "$$ \\frac{\\p \\bff(\\bfg(\\bfx)) }{\\p \\bfx} = \\frac{\\p \\bff}{\\p \\bfg}\\frac{\\p \\bfg}{\\p \\bfx}$$,\n",
    "\n",
    "for any function $\\bfg : \\bbR^n \\mapsto \\bbR^m$ and $\\bff : \\bbR^m \\mapsto \\bbR^o$.\n",
    "\n",
    "Show that for $\\bfx \\in \\bbR^n$ amd $\\bfA \\in \\bbR^{n \\times n}$\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\p }{ \\p \\bfx} \\bfx^\\top \\bfA \\bfx = \\bfx^\\top (\\bfA^\\top + \\bfA)\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb1f07c-3891-4f30-909a-69f0e5c3f371",
   "metadata": {
    "tags": []
   },
   "source": [
    "A22:\n",
    "\n",
    "For product of any two vectors\n",
    "\\begin{align}\n",
    "\\frac{\\p }{\\p \\bfx} \\bfx^\\top \\bfy = \\bfy^\\top\n",
    "\\end{align}\n",
    "If $\\bfy$ is a function of $\\bfx$, then\n",
    "\\begin{align}\n",
    "\\frac{\\p }{\\p \\bfx} \\bfx^\\top \\bfy &= \\bfy^\\top + \n",
    "\\left(\\frac{\\p }{\\p \\bfy} \\bfx^\\top \\bfy \\right) \\left(\\frac{\\p \\bfy }{\\p \\bfx}  \\right)\\\\\n",
    "&= \\bfy^\\top + \\bfx^\\top \\left(\\frac{\\p \\bfy }{\\p \\bfx}\\right)\n",
    "\\end{align}\n",
    "If $\\bfy = \\bfA \\bfx$, then \n",
    "$$\\frac{\\p \\bfy}{\\p \\bfx} = \\frac{\\p }{\\p \\bfx} \\bfA \\bfx = \\bfA$$\n",
    "and \n",
    "\n",
    "$$\\frac{\\p }{\\p \\bfx} \\bfx^\\top \\bfA \\bfx = \n",
    "\\bfy^\\top + \\bfx^\\top \\left(\\frac{\\p \\bfy }{\\p \\bfx}\\right)\n",
    "= \\bfx^\\top \\bfA^\\top + \\bfx^\\top \\bfA \n",
    "= \\bfx^\\top (\\bfA^\\top + \\bfA)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6455d414-9dbf-4328-95c9-9a5bb1b7424c",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff58c0a-8fbf-4074-a2ad-3075fbd5efb1",
   "metadata": {},
   "source": [
    "##### Q23:\n",
    "\n",
    "You are given 2D points and corresponding labels as a training dataset $\\{ (x_1, y_1, l_1), (x_2, y_2, l_2), \\dots, (x_n, y_n, l_n) \\}$, where $x_i \\in \\bbR$, $y_i \\in \\bbR$ and the labels $l_i \\in \\{-1, 1\\}$. Use the model \n",
    "$\\hat{l}_i = \\sign(y_i - (m x_i + c))$ to construct a loss (or error) function. Find the gradient of the loss function with respect to the vector $\\bfm = [m; c]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd22e867-2ce2-4322-816c-6b653b9e33c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "A23\n",
    "\n",
    "$$ e(y_i, x_i; m,c) = \\begin{cases}\n",
    "0 &\\text{ if }\\sign(y_i - (m x_i + c))  = l_i\\\\\n",
    "|y_i - (m x_i + c)| &\\text{ if }  \\sign(y_i - (m x_i + c))  \\ne l_i\n",
    "\\end{cases}$$\n",
    "\n",
    "$$\\bfm = \\begin{bmatrix}m \\\\ c\\end{bmatrix}$$\n",
    "\n",
    "$$ e(y_i, x_i;\\bfm) = \\begin{cases}\n",
    "0 &\\text{ if } \\sign( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm)  = l_i\\\\\n",
    "|y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm| &\\text{ if }  \\sign( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm)  \\ne l_i\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "If $l_i \\in \\{-1, 1\\}$, then  $\\sign( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm)  = l_i $ is same as saying\n",
    "$ l_i( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm) > 0$.\n",
    "\n",
    "\n",
    "\n",
    "$$ e(y_i, x_i;\\bfm) = \\begin{cases}\n",
    "0 &\\text{ if } l_i( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm) > 0\\\\\n",
    "|l_i( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm)| &\\text{ if } l_i( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm) < 0\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "Also when $z < 0$, then $|z| = -z$. \n",
    "\n",
    "$$ e(y_i, x_i;\\bfm) = \\begin{cases}\n",
    "0 &\\text{ if } l_i( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm) > 0\\\\\n",
    "-l_i( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm) &\\text{ if } l_i( y_i - \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm) < 0\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "$$ e(y_i, x_i;\\bfm) =  \\max\\{0, - l_i (y_i -  \\begin{bmatrix} x_i& 1\\end{bmatrix}\\bfm)\\} $$\n",
    "$$ \\nabla_\\bfm e(y_i, x_i;\\bfm) = \\max\\{0, l_i(\\begin{bmatrix} x_i& 1\\end{bmatrix})\\} $$\n",
    "\n",
    "For the entire dataset, we have $\\bfy = [y_1; \\dots; y_n]$ and $\\bfx = [x_1; \\dots; x_n]$, $\\bfl = [l_1; \\dots; l_n]$ the average error is:\n",
    "$$ e(\\bfx, \\bfy; \\bfm) = \\frac{1}{n}{\\bfone_n^\\top}\\max\\{0, - \\bfl \\odot (\\bfy - \\begin{bmatrix}\\bfx  &  \\bfone_n\\end{bmatrix}\\bfm )\\},$$\n",
    "\n",
    "where $\\odot$ is the element-wise product. and $\\bfone_n$ is a vector of ones.\n",
    "\n",
    "and the average gradient is:\n",
    "$$ \\nabla_\\bfm^\\top e(\\bfx, \\bfy; \\bfm) = \\frac{1}{n}{\\bfone_n^\\top}\\max\\{0,  \\bfl \\odot ( \\begin{bmatrix}\\bfx  &  \\bfone_n\\end{bmatrix} )\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24fd2d5-7118-4204-bf6f-2fcda8578e43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "##### Q24\n",
    "\n",
    "You are given p-D points $\\bfx_i \\in \\bbR^p$ and corresponding labels as a training dataset $\\{ (\\bfx_1, l_1), (\\bfx_2, l_2), \\dots, (\\bfx_n, l_n) \\}$, where $\\bfx_i \\in \\bbR^p$, and the labels $l_i \\in \\{-1, 1\\}$. Use the model \n",
    "$\\hat{l}_i = \\sign(\\bfx_i^\\top \\bfm + m_0))$ to construct a loss (or error) function. Find the gradient of the loss function with respect to the vector $\\bfq = [m_0; \\bfm]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc7b84c-a84b-49c6-b805-e356256092c0",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "A24:\n",
    "\n",
    "$$ e(m_0, \\bfm; \\bfx_i) = \\begin{cases}\n",
    "0 &\\text{ if }\\sign(\\bfx_i^\\top \\bfm + m_0)  = l_i\\\\\n",
    "|\\bfx_i^\\top \\bfm + m_0| &\\text{ if }  \\sign(\\bfx_i^\\top \\bfm + m_0)  \\ne l_i\n",
    "\\end{cases}$$\n",
    "\n",
    "$$ e(y_i, x_i; m, c) = \\begin{cases}\n",
    "0 &\\text{ if } \\sign(\\bfx_i^\\top \\bfm + m_0)  = l_i\\\\\n",
    "|\\bfx_i^\\top \\bfm + m_0| &\\text{ if }  \\sign(\\bfx_i^\\top \\bfm + m_0)  \\ne l_i\n",
    "\\end{cases}$$\n",
    "\n",
    "$$\\bfq = \\begin{bmatrix}m_0 \\\\ \\bfm\\end{bmatrix}$$\n",
    "\n",
    "$$ e(m_0, \\bfm;\\bfx_i) = \\begin{cases}\n",
    "0 &\\text{ if } \\begin{bmatrix} 1 & \\bfx_i^\\top\\end{bmatrix}\\bfq  = l_i\\\\\n",
    "|\\begin{bmatrix} 1 & \\bfx_i^\\top\\end{bmatrix}\\bfq| &\\text{ if }  \\begin{bmatrix} 1 & \\bfx_i^\\top\\end{bmatrix}\\bfq  \\ne l_i\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "If $l_i \\in \\{-1, 1\\}$, then we can write\n",
    "\n",
    "$$ e(m_0, \\bfm;\\bfx_i) =  \\max\\{0, - l_i (\\begin{bmatrix} 1 & \\bfx_i^\\top\\end{bmatrix}\\bfq)\\} $$\n",
    "$$ \\nabla_\\bfm e(m_0, \\bfm;\\bfx_i) = \\max\\{0, - l_i (\\begin{bmatrix} 1 & \\bfx_i^\\top\\end{bmatrix})\\} $$\n",
    "\n",
    "For the entire dataset, we have $\\bfX = [\\bfx_1^\\top; \\dots; \\bfx_n^\\top]$, $\\bfl = [l_1; \\dots; l_n]$ the average error is:\n",
    "$$ e(\\bfm; \\bfX, \\bfl) = \\frac{1}{n}{\\bfone_n^\\top}\\max\\{0, - \\bfl \\odot ( \\begin{bmatrix}\\bfone_n & \\bfX \\end{bmatrix}\\bfq )\\}$$\n",
    "\n",
    "and the average gradient is:\n",
    "$$ \\nabla_\\bfm^\\top e(\\bfm; \\bfX, \\bfl) = \\frac{1}{n}{\\bfone_n^\\top}\\max\\{0,  \\bfl \\odot ( \\begin{bmatrix}  \\bfone_n & \\bfX \\end{bmatrix} )\\}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
