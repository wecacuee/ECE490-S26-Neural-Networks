{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Residual Networks (ResNets)\n",
    "exports:\n",
    "  - format: pdf\n",
    "    template: plain_latex\n",
    "    output: exports/ResNets.pdf\n",
    "    logo: false\n",
    "    link: true\n",
    "downloads:\n",
    "  - file: exports/ResNets.pdf\n",
    "  - file: ResNets.ipynb\n",
    "math:\n",
    "    '\\calA': '{\\cal A}'\n",
    "    '\\calB': '{\\cal B}'\n",
    "    '\\calC': '{\\cal C}'\n",
    "    '\\calD': '{\\cal D}'\n",
    "    '\\calE': '{\\cal E}'\n",
    "    '\\calF': '{\\cal F}'\n",
    "    '\\calG': '{\\cal G}'\n",
    "    '\\calH': '{\\cal H}'\n",
    "    '\\calI': '{\\cal I}'\n",
    "    '\\calJ': '{\\cal J}'\n",
    "    '\\calK': '{\\cal K}'\n",
    "    '\\calL': '{\\cal L}'\n",
    "    '\\calM': '{\\cal M}'\n",
    "    '\\calN': '{\\cal N}'\n",
    "    '\\calO': '{\\cal O}'\n",
    "    '\\calP': '{\\cal P}'\n",
    "    '\\calQ': '{\\cal Q}'\n",
    "    '\\calR': '{\\cal R}'\n",
    "    '\\calS': '{\\cal S}'\n",
    "    '\\calT': '{\\cal T}'\n",
    "    '\\calU': '{\\cal U}'\n",
    "    '\\calV': '{\\cal V}'\n",
    "    '\\calW': '{\\cal W}'\n",
    "    '\\calX': '{\\cal X}'\n",
    "    '\\calY': '{\\cal Y}'\n",
    "    '\\calZ': '{\\cal Z}'\n",
    "    '\\bfa': '\\mathbf{a}'\n",
    "    '\\bfb': '\\mathbf{b}'\n",
    "    '\\bfc': '\\mathbf{c}'\n",
    "    '\\bfd': '\\mathbf{d}'\n",
    "    '\\bfe': '\\mathbf{e}'\n",
    "    '\\bff': '\\mathbf{f}'\n",
    "    '\\bfg': '\\mathbf{g}'\n",
    "    '\\bfh': '\\mathbf{h}'\n",
    "    '\\bfi': '\\mathbf{i}'\n",
    "    '\\bfj': '\\mathbf{j}'\n",
    "    '\\bfk': '\\mathbf{k}'\n",
    "    '\\bfl': '\\mathbf{l}'\n",
    "    '\\bfm': '\\mathbf{m}'\n",
    "    '\\bfn': '\\mathbf{n}'\n",
    "    '\\bfo': '\\mathbf{o}'\n",
    "    '\\bfp': '\\mathbf{p}'\n",
    "    '\\bfq': '\\mathbf{q}'\n",
    "    '\\bfr': '\\mathbf{r}'\n",
    "    '\\bfs': '\\mathbf{s}'\n",
    "    '\\bft': '\\mathbf{t}'\n",
    "    '\\bfu': '\\mathbf{u}'\n",
    "    '\\bfv': '\\mathbf{v}'\n",
    "    '\\bfw': '\\mathbf{w}'\n",
    "    '\\bfx': '\\mathbf{x}'\n",
    "    '\\bfy': '\\mathbf{y}'\n",
    "    '\\bfz': '\\mathbf{z}'\n",
    "    '\\bfW': '\\mathbf{W}'\n",
    "    '\\bfX': '\\mathbf{X}'\n",
    "    '\\bfY': '\\mathbf{Y}'\n",
    "    '\\bfZ': '\\mathbf{Z}'\n",
    "    '\\bftheta': '\\boldsymbol{\\theta}'\n",
    "    '\\bbR': '\\mathbb{R}'\n",
    "    '\\bbE': '\\mathbb{E}'\n",
    "    '\\p': '\\partial'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks (ResNets)\n",
    "\n",
    "In this notebook, we will explore:\n",
    "1. Why deep networks are hard to train (the degradation problem)\n",
    "2. How residual connections solve this problem\n",
    "3. Implementation of ResNet building blocks\n",
    "4. He initialization for ReLU networks\n",
    "5. Training ResNets on CIFAR-10\n",
    "\n",
    "**Prerequisites**: CNN notebook (07-cnn), Vanishing Gradients (09-vanishing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: otter-grader in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (6.1.4)\n",
      "Requirement already satisfied: torch in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: matplotlib in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (8.2.1)\n",
      "Requirement already satisfied: dill>=0.3.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (0.4.0)\n",
      "Requirement already satisfied: fica>=0.4.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (0.4.1)\n",
      "Requirement already satisfied: ipylab<2.0.0,>=1.0.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (1.1.0)\n",
      "Requirement already satisfied: ipython in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (8.37.0)\n",
      "Requirement already satisfied: ipywidgets<9.0.0,>=8.1.5 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (8.1.7)\n",
      "Requirement already satisfied: jinja2<4.0,>=3.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (3.1.6)\n",
      "Requirement already satisfied: jupytext<2.0.0,>=1.16.4 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (1.17.3)\n",
      "Requirement already satisfied: nbconvert>=6.0.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.0.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (5.10.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (2.3.2)\n",
      "Requirement already satisfied: python-on-whales<1.0.0,>=0.72.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (0.78.0)\n",
      "Requirement already satisfied: pyyaml<7,>=6 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (6.0.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (2.32.5)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.16.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from otter-grader) (1.17.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (0.2.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (3.0.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jinja2<4.0,>=3.1->otter-grader) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (4.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (0.5.0)\n",
      "Requirement already satisfied: packaging in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (25.0)\n",
      "Requirement already satisfied: tomli in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (2.2.1)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=2 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from requests<3.0,>=2.31->otter-grader) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from requests<3.0,>=2.31->otter-grader) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from requests<3.0,>=2.31->otter-grader) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from requests<3.0,>=2.31->otter-grader) (2025.8.3)\n",
      "Requirement already satisfied: filelock in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: numpy in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: docutils in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from fica>=0.4.1->otter-grader) (0.21.2)\n",
      "Requirement already satisfied: sphinx in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from fica>=0.4.1->otter-grader) (8.1.3)\n",
      "Requirement already satisfied: decorator in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipython->otter-grader) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipython->otter-grader) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipython->otter-grader) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipython->otter-grader) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipython->otter-grader) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipython->otter-grader) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipython->otter-grader) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from ipython->otter-grader) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->otter-grader) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jedi>=0.16->ipython->otter-grader) (0.8.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from markdown-it-py>=1.0->jupytext<2.0.0,>=1.16.4->otter-grader) (0.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (5.8.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.4.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jupyter-core>=4.7->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.2.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (8.6.3)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (27.0.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (6.5.2)\n",
      "Requirement already satisfied: playwright in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.55.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbformat>=5.0.0->otter-grader) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from nbformat>=5.0.0->otter-grader) (4.25.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (0.27.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from pandas>=2.0.0->otter-grader) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from pandas>=2.0.0->otter-grader) (2025.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from pexpect>4.3->ipython->otter-grader) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (2.8)\n",
      "Requirement already satisfied: pyee<14,>=13 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (13.0.0)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (3.2.4)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: snowballstemmer>=2.2 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (3.0.1)\n",
      "Requirement already satisfied: babel>=2.13 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.17.0)\n",
      "Requirement already satisfied: alabaster>=0.7.14 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.0)\n",
      "Requirement already satisfied: imagesize>=1.3 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.4.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from stack_data->ipython->otter-grader) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from stack_data->ipython->otter-grader) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/vdhiman/.local/venvs/ece490/lib/python3.10/site-packages (from stack_data->ipython->otter-grader) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install otter-grader torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not download tests. Grading may not work.\n"
     ]
    }
   ],
   "source": [
    "# Setup otter-grader\n",
    "URL = \"https://raw.githubusercontent.com/wecacuee/ECE490-F25-Neural-Networks/refs/heads/master/notebooks/11-regularization-resnets/ResNetsTests.zip\"\n",
    "fname = \"ResNetsTests.zip\"\n",
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "try:\n",
    "    urllib.request.urlretrieve(URL, fname)\n",
    "    ZipFile(fname).extractall()\n",
    "except:\n",
    "    print(\"Could not download tests. Grading may not work.\")\n",
    "import otter\n",
    "grader = otter.Notebook(tests_dir=\"./tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Degradation Problem\n",
    "\n",
    "A surprising observation: adding more layers to a deep network can actually **increase** training error.\n",
    "\n",
    "This is NOT overfitting (validation error is also higher). The problem is that deeper networks are harder to optimize.\n",
    "\n",
    "![Degradation Problem](https://miro.medium.com/max/1400/1*vbx2sDfjB9YB5PEI3j2BXg.png)\n",
    "\n",
    "**Key insight**: If we could learn identity mappings for the extra layers, a deeper network should be at least as good as a shallower one. But in practice, this is hard to learn with standard gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57.7%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain Network (No Skip Connections)\n",
    "\n",
    "Let's first build a plain CNN without skip connections to demonstrate the degradation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shallow PlainNet parameters: 4,729,418\n",
      "Deep PlainNet parameters: 17,270,858\n"
     ]
    }
   ],
   "source": [
    "class PlainBlock(nn.Module):\n",
    "    \"\"\"A plain convolutional block without skip connections\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class PlainNet(nn.Module):\n",
    "    \"\"\"Plain network without skip connections\"\"\"\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = [block(self.in_channels, out_channels, stride)]\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Create a shallow and deep plain network\n",
    "plain_shallow = PlainNet(PlainBlock, [1, 1, 1, 1])  # ~10 layers\n",
    "plain_deep = PlainNet(PlainBlock, [3, 3, 3, 3])      # ~26 layers\n",
    "\n",
    "print(f\"Shallow PlainNet parameters: {sum(p.numel() for p in plain_shallow.parameters()):,}\")\n",
    "print(f\"Deep PlainNet parameters: {sum(p.numel() for p in plain_deep.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Residual Learning: The Solution\n",
    "\n",
    "Instead of hoping each stack of layers directly fits a desired underlying mapping $\\calH(\\bfx)$, we explicitly let these layers fit a **residual mapping**:\n",
    "\n",
    "$$\\calF(\\bfx) = \\calH(\\bfx) - \\bfx$$\n",
    "\n",
    "The original mapping becomes:\n",
    "\n",
    "$$\\calH(\\bfx) = \\calF(\\bfx) + \\bfx$$\n",
    "\n",
    "**Key insight**: If the identity mapping is optimal, it's easier to push the residual $\\calF(\\bfx)$ to zero than to fit an identity mapping with nonlinear layers.\n",
    "\n",
    "```\n",
    "x ─────────────────────(+)──→ y\n",
    "  │                     ↑\n",
    "  └──→ [Conv] → [BN] → [ReLU] → [Conv] → [BN] ─┘\n",
    "              F(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Flow Through Residual Connections\n",
    "\n",
    "For a residual block $\\bfy = \\calF(\\bfx) + \\bfx$, the gradient is:\n",
    "\n",
    "$$\\frac{\\p \\calL}{\\p \\bfx} = \\frac{\\p \\calL}{\\p \\bfy} \\cdot \\frac{\\p \\bfy}{\\p \\bfx} = \\frac{\\p \\calL}{\\p \\bfy} \\cdot \\left(1 + \\frac{\\p \\calF}{\\p \\bfx}\\right)$$\n",
    "\n",
    "The **identity path** (the $+1$ term) ensures gradients can flow directly backward, even if $\\frac{\\p \\calF}{\\p \\bfx}$ is small.\n",
    "\n",
    "For a network with $L$ residual blocks:\n",
    "\n",
    "$$\\frac{\\p \\calL}{\\p \\bfx_0} = \\frac{\\p \\calL}{\\p \\bfx_L} \\cdot \\prod_{l=1}^{L} \\left(1 + \\frac{\\p \\calF_l}{\\p \\bfx_{l-1}}\\right)$$\n",
    "\n",
    "The gradient always has a path through the identity connections!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing ResNet Blocks\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Exercise 1: Implement BasicBlock (15 points)\n",
    "\n",
    "Implement the basic residual block used in ResNet-18 and ResNet-34.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "x → Conv3x3 → BN → ReLU → Conv3x3 → BN → (+) → ReLU → out\n",
    "|_______________________________________↑ (skip connection)\n",
    "```\n",
    "\n",
    "When `stride > 1` or input/output channels differ, use a 1x1 convolution for the skip connection (provided via `downsample`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic residual block: two 3x3 convolutions with skip connection\n",
    "    \n",
    "    Args:\n",
    "        in_channels: Number of input channels\n",
    "        out_channels: Number of output channels\n",
    "        stride: Stride for first convolution (default: 1)\n",
    "        downsample: Module for downsampling identity if dimensions change (default: None)\n",
    "    \"\"\"\n",
    "    expansion = 1  # Output channels = out_channels * expansion\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        # TODO: Implement the following layers:\n",
    "        # self.conv1: 3x3 conv, in_channels -> out_channels, with stride, padding=1, no bias\n",
    "        # self.bn1: BatchNorm2d for out_channels\n",
    "        # self.conv2: 3x3 conv, out_channels -> out_channels, stride=1, padding=1, no bias\n",
    "        # self.bn2: BatchNorm2d for out_channels\n",
    "        # self.downsample: store the downsample module\n",
    "        \n",
    "        self.conv1 = ...  # YOUR CODE HERE\n",
    "        self.bn1 = ...    # YOUR CODE HERE\n",
    "        self.conv2 = ...  # YOUR CODE HERE\n",
    "        self.bn2 = ...    # YOUR CODE HERE\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass with skip connection.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, in_channels, H, W)\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of shape (batch, out_channels, H', W')\n",
    "            where H', W' depend on stride\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass\n",
    "        # 1. Store identity (x) for skip connection\n",
    "        # 2. Apply conv1 -> bn1 -> relu\n",
    "        # 3. Apply conv2 -> bn2\n",
    "        # 4. If downsample is not None, apply it to identity\n",
    "        # 5. Add identity to output (skip connection)\n",
    "        # 6. Apply final relu\n",
    "        \n",
    "        identity = x\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        out = ...\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your BasicBlock implementation\n",
    "def test_basic_block():\n",
    "    # Test 1: Same dimensions\n",
    "    block = BasicBlock(64, 64)\n",
    "    x = torch.randn(2, 64, 32, 32)\n",
    "    y = block(x)\n",
    "    assert y.shape == (2, 64, 32, 32), f\"Expected (2, 64, 32, 32), got {y.shape}\"\n",
    "    \n",
    "    # Test 2: With downsampling\n",
    "    downsample = nn.Sequential(\n",
    "        nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "        nn.BatchNorm2d(128)\n",
    "    )\n",
    "    block = BasicBlock(64, 128, stride=2, downsample=downsample)\n",
    "    x = torch.randn(2, 64, 32, 32)\n",
    "    y = block(x)\n",
    "    assert y.shape == (2, 128, 16, 16), f\"Expected (2, 128, 16, 16), got {y.shape}\"\n",
    "    \n",
    "    print(\"BasicBlock tests passed!\")\n",
    "\n",
    "test_basic_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"basic_block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement BottleneckBlock (15 points)\n",
    "\n",
    "For deeper networks (ResNet-50+), we use **bottleneck blocks** to reduce computation:\n",
    "\n",
    "```\n",
    "x → Conv1x1 → BN → ReLU → Conv3x3 → BN → ReLU → Conv1x1 → BN → (+) → ReLU → out\n",
    "|     (reduce)              (process)              (expand)        ↑\n",
    "|______________________________________________________________↑ (skip)\n",
    "```\n",
    "\n",
    "The 1x1 convolutions reduce channels before the expensive 3x3 convolution, then expand back.\n",
    "\n",
    "- First 1x1: `in_channels` → `out_channels`\n",
    "- 3x3: `out_channels` → `out_channels`  \n",
    "- Second 1x1: `out_channels` → `out_channels * expansion` (where expansion=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck residual block: 1x1 -> 3x3 -> 1x1 with skip connection\n",
    "    \n",
    "    The expansion factor means output has out_channels * 4 channels.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        # TODO: Implement the following layers:\n",
    "        # self.conv1: 1x1 conv, in_channels -> out_channels, no bias\n",
    "        # self.bn1: BatchNorm2d\n",
    "        # self.conv2: 3x3 conv, out_channels -> out_channels, with stride, padding=1, no bias\n",
    "        # self.bn2: BatchNorm2d\n",
    "        # self.conv3: 1x1 conv, out_channels -> out_channels * expansion, no bias\n",
    "        # self.bn3: BatchNorm2d\n",
    "        \n",
    "        self.conv1 = ...  # YOUR CODE HERE\n",
    "        self.bn1 = ...    # YOUR CODE HERE\n",
    "        self.conv2 = ...  # YOUR CODE HERE\n",
    "        self.bn2 = ...    # YOUR CODE HERE\n",
    "        self.conv3 = ...  # YOUR CODE HERE\n",
    "        self.bn3 = ...    # YOUR CODE HERE\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # TODO: Implement forward pass\n",
    "        # 1. conv1 -> bn1 -> relu\n",
    "        # 2. conv2 -> bn2 -> relu\n",
    "        # 3. conv3 -> bn3\n",
    "        # 4. Apply downsample to identity if needed\n",
    "        # 5. Add skip connection\n",
    "        # 6. Final relu\n",
    "        \n",
    "        out = ...  # YOUR CODE HERE\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test BottleneckBlock\n",
    "def test_bottleneck():\n",
    "    # Test with downsample (typical first block in a stage)\n",
    "    downsample = nn.Sequential(\n",
    "        nn.Conv2d(64, 256, kernel_size=1, stride=1, bias=False),\n",
    "        nn.BatchNorm2d(256)\n",
    "    )\n",
    "    block = BottleneckBlock(64, 64, stride=1, downsample=downsample)\n",
    "    x = torch.randn(2, 64, 32, 32)\n",
    "    y = block(x)\n",
    "    assert y.shape == (2, 256, 32, 32), f\"Expected (2, 256, 32, 32), got {y.shape}\"\n",
    "    \n",
    "    # Test with stride=2\n",
    "    downsample = nn.Sequential(\n",
    "        nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
    "        nn.BatchNorm2d(512)\n",
    "    )\n",
    "    block = BottleneckBlock(256, 128, stride=2, downsample=downsample)\n",
    "    x = torch.randn(2, 256, 32, 32)\n",
    "    y = block(x)\n",
    "    assert y.shape == (2, 512, 16, 16), f\"Expected (2, 512, 16, 16), got {y.shape}\"\n",
    "    \n",
    "    print(\"BottleneckBlock tests passed!\")\n",
    "\n",
    "test_bottleneck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"bottleneck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 4. He Initialization\n",
    "\n",
    "For deep networks with ReLU, proper weight initialization is crucial.\n",
    "\n",
    "### Variance Propagation Analysis\n",
    "\n",
    "Consider a linear layer $\\bfy = \\bfW\\bfx$ where:\n",
    "- $x_i \\sim \\text{i.i.d.}$ with $\\bbE[x_i] = 0$, $\\text{Var}(x_i) = \\sigma_x^2$\n",
    "- $W_{ij} \\sim \\text{i.i.d.}$ with $\\bbE[W_{ij}] = 0$, $\\text{Var}(W_{ij}) = \\sigma_W^2$\n",
    "\n",
    "The output variance is:\n",
    "$$\\text{Var}(y_j) = n_{in} \\cdot \\sigma_W^2 \\cdot \\sigma_x^2$$\n",
    "\n",
    "**For variance preservation**: $\\sigma_W^2 = \\frac{1}{n_{in}}$ (Xavier/Glorot initialization)\n",
    "\n",
    "**With ReLU**, half the values are zeroed on average, so:\n",
    "$$\\sigma_W^2 = \\frac{2}{n_{in}} \\quad \\text{(He initialization)}$$\n",
    "\n",
    "$$W \\sim \\calN\\left(0, \\sqrt{\\frac{2}{n_{in}}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Verify He Initialization (10 points)\n",
    "\n",
    "Implement a function to verify that He initialization maintains unit variance through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_he_init(model, input_shape=(64, 3, 32, 32)):\n",
    "    \"\"\"\n",
    "    Verify that activations maintain approximately unit variance through the network.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        input_shape: Shape of input tensor (batch, channels, height, width)\n",
    "        \n",
    "    Returns:\n",
    "        variances: List of variance values at each layer\n",
    "        layer_names: List of layer names\n",
    "    \"\"\"\n",
    "    variances = []\n",
    "    layer_names = []\n",
    "    \n",
    "    # TODO: \n",
    "    # 1. Create random input with unit variance\n",
    "    # 2. Register forward hooks on Conv2d and Linear layers to capture activations\n",
    "    # 3. Run forward pass\n",
    "    # 4. Compute variance of each layer's output\n",
    "    # 5. Return list of variances\n",
    "    \n",
    "    # Hint: Use model.named_modules() to iterate over layers\n",
    "    # Hint: Use register_forward_hook to capture layer outputs\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    x = torch.randn(input_shape)  # Unit variance input\n",
    "    \n",
    "    # Store activations\n",
    "    activations = {}\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(module, input, output):\n",
    "            activations[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    # Register hooks\n",
    "    handles = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            handles.append(module.register_forward_hook(get_activation(name)))\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        model(x)\n",
    "    \n",
    "    # Remove hooks\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "    \n",
    "    # Compute variances\n",
    "    for name, act in activations.items():\n",
    "        var = act.var().item()\n",
    "        variances.append(var)\n",
    "        layer_names.append(name)\n",
    "    \n",
    "    return variances, layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize variance propagation\n",
    "def plot_variance_propagation(variances, layer_names, title=\"Variance through layers\"):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(range(len(variances)), variances)\n",
    "    plt.axhline(y=1.0, color='r', linestyle='--', label='Target variance=1')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Variance')\n",
    "    plt.title(title)\n",
    "    plt.xticks(range(len(variances)), layer_names, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test with a simple model using He init\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1, stride=2)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.fc = nn.Linear(128 * 16 * 16, 10)\n",
    "        \n",
    "        # Apply He initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "simple_net = SimpleNet()\n",
    "variances, names = verify_he_init(simple_net)\n",
    "plot_variance_propagation(variances, names, \"Variance with He Initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"he_init\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building the Full ResNet\n",
    "\n",
    "Now let's assemble our blocks into a complete ResNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet architecture for CIFAR-10.\n",
    "    \n",
    "    Args:\n",
    "        block: BasicBlock or BottleneckBlock\n",
    "        layers: List of number of blocks in each stage [2, 2, 2, 2] for ResNet-18\n",
    "        num_classes: Number of output classes\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        # Initial convolution (adapted for CIFAR-10's 32x32 images)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Residual stages\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = [block(self.in_channels, out_channels, stride, downsample)]\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(BottleneckBlock, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet-18\n",
    "resnet18 = ResNet18()\n",
    "print(f\"ResNet-18 parameters: {sum(p.numel() for p in resnet18.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(2, 3, 32, 32)\n",
    "y = resnet18(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training ResNet on CIFAR-10\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Exercise 4: Train ResNet-18 (15 points)\n",
    "\n",
    "Train ResNet-18 on CIFAR-10 to achieve >75% test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, trainloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "    return running_loss / len(trainloader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, testloader, criterion, device):\n",
    "    \"\"\"Evaluate on test set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "    return running_loss / len(testloader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(epochs=10):\n",
    "    \"\"\"\n",
    "    Train ResNet-18 on CIFAR-10.\n",
    "    \n",
    "    Args:\n",
    "        epochs: Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained ResNet-18 model\n",
    "        test_acc: Final test accuracy (must be > 75%)\n",
    "        history: Dict with 'train_loss', 'train_acc', 'test_loss', 'test_acc' lists\n",
    "    \"\"\"\n",
    "    # TODO: Implement training\n",
    "    # 1. Create ResNet-18 model and move to device\n",
    "    # 2. Define loss function (CrossEntropyLoss)\n",
    "    # 3. Define optimizer (SGD with momentum=0.9, weight_decay=5e-4)\n",
    "    # 4. Optionally use learning rate scheduler\n",
    "    # 5. Train for specified epochs, tracking metrics\n",
    "    \n",
    "    model = ResNet18().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, trainloader, criterion, optimizer, DEVICE)\n",
    "        test_loss, test_acc = evaluate(model, testloader, criterion, DEVICE)\n",
    "        scheduler.step()\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    return model, test_acc, history\n",
    "\n",
    "# Train the model (set epochs based on available compute)\n",
    "# For quick testing, use fewer epochs; for best results, use 50-100\n",
    "trained_model, final_acc, history = train_resnet(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['test_loss'], label='Test')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Loss Curves')\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='Train')\n",
    "axes[1].plot(history['test_acc'], label='Test')\n",
    "axes[1].axhline(y=75, color='r', linestyle='--', label='Target (75%)')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Accuracy Curves')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {final_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"train_resnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Ablation Study (10 points)\n",
    "\n",
    "Compare different configurations to understand the impact of BatchNorm and Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_study(epochs=10):\n",
    "    \"\"\"\n",
    "    Compare ResNet configurations:\n",
    "    1. Standard ResNet with BatchNorm\n",
    "    2. ResNet without BatchNorm (replace with Identity)\n",
    "    3. ResNet with Dropout after each block\n",
    "    \n",
    "    Returns:\n",
    "        results: Dict with accuracy for each configuration\n",
    "                 {'with_bn': float, 'without_bn': float, 'with_dropout': float}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Implement ablation study\n",
    "    # Train each configuration for specified epochs\n",
    "    # Store final test accuracy in results dict\n",
    "    \n",
    "    # Configuration 1: Standard ResNet with BatchNorm\n",
    "    print(\"Training ResNet with BatchNorm...\")\n",
    "    model_bn = ResNet18().to(DEVICE)\n",
    "    # ... train and evaluate\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run ablation study (use fewer epochs for quick testing)\n",
    "# ablation_results = ablation_study(epochs=10)\n",
    "# print(\"\\nAblation Study Results:\")\n",
    "# for config, acc in ablation_results.items():\n",
    "#     print(f\"  {config}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check(\"ablation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 7. Loss Landscape Visualization\n",
    "\n",
    "One reason ResNets train better is that skip connections **smooth the loss landscape**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_landscape_1d(model, dataloader, device, n_points=21):\n",
    "    \"\"\"\n",
    "    Plot 1D slice of loss landscape along a random direction.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Save original parameters\n",
    "    original_params = [p.clone() for p in model.parameters()]\n",
    "    \n",
    "    # Generate random direction\n",
    "    direction = [torch.randn_like(p) for p in model.parameters()]\n",
    "    # Normalize direction\n",
    "    d_norm = sum((d**2).sum() for d in direction).sqrt()\n",
    "    direction = [d / d_norm for d in direction]\n",
    "    \n",
    "    # Compute loss along direction\n",
    "    alphas = np.linspace(-1, 1, n_points)\n",
    "    losses = []\n",
    "    \n",
    "    # Get a single batch\n",
    "    inputs, labels = next(iter(dataloader))\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        # Perturb parameters\n",
    "        with torch.no_grad():\n",
    "            for p, p0, d in zip(model.parameters(), original_params, direction):\n",
    "                p.copy_(p0 + alpha * d)\n",
    "        \n",
    "        # Compute loss\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    # Restore original parameters\n",
    "    with torch.no_grad():\n",
    "        for p, p0 in zip(model.parameters(), original_params):\n",
    "            p.copy_(p0)\n",
    "    \n",
    "    return alphas, losses\n",
    "\n",
    "# Compare loss landscapes\n",
    "if 'trained_model' in dir():\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # ResNet loss landscape\n",
    "    alphas, losses = plot_loss_landscape_1d(trained_model, testloader, DEVICE)\n",
    "    plt.plot(alphas, losses, label='ResNet-18')\n",
    "    \n",
    "    plt.xlabel('Step along random direction')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Landscape (1D slice)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Regularization Techniques Recap\n",
    "\n",
    "### Dropout\n",
    "During training, randomly zero activations with probability $p$:\n",
    "$$\\tilde{h}_i = \\begin{cases} 0 & \\text{with prob } p \\\\ h_i / (1-p) & \\text{with prob } 1-p \\end{cases}$$\n",
    "\n",
    "### Batch Normalization\n",
    "Normalize activations across the batch:\n",
    "$$\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}, \\quad y_i = \\gamma \\hat{x}_i + \\beta$$\n",
    "\n",
    "### Weight Decay (L2 regularization)\n",
    "Add penalty on weight magnitude:\n",
    "$$\\calL_{reg} = \\calL + \\frac{\\lambda}{2} \\|\\bfW\\|_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extensions: DenseNet and U-Net\n",
    "\n",
    "### DenseNet\n",
    "Each layer receives feature maps from ALL preceding layers:\n",
    "$$\\bfx_l = H_l([\\bfx_0, \\bfx_1, \\ldots, \\bfx_{l-1}])$$\n",
    "\n",
    "### U-Net\n",
    "Encoder-decoder architecture with skip connections between corresponding layers:\n",
    "- **Encoder**: Downsample path (like ResNet)\n",
    "- **Decoder**: Upsample path\n",
    "- **Skip connections**: Connect encoder layers to decoder layers at same resolution\n",
    "\n",
    "Used extensively in image segmentation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. **Degradation Problem**: Deeper networks can have higher training error\n",
    "2. **Residual Learning**: Learn $\\calF(\\bfx) = \\calH(\\bfx) - \\bfx$ instead of $\\calH(\\bfx)$\n",
    "3. **Skip Connections**: Enable direct gradient flow through identity path\n",
    "4. **He Initialization**: Use $\\sigma_W = \\sqrt{2/n_{in}}$ for ReLU networks\n",
    "5. **Building Blocks**: BasicBlock for ResNet-18/34, BottleneckBlock for deeper\n",
    "6. **Loss Landscape**: Skip connections smooth the optimization landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in order before exporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export\n",
    "grader.export(run_tests=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
