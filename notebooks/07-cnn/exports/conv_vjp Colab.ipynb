{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3ebe2e-ff09-41c8-8545-c7c116c13b78",
   "metadata": {},
   "source": [
    "LaTeX math aliases\n",
    "\n",
    "$$\n",
    "% Calligraphic fonts\n",
    "\\newcommand{\\calA}{{\\cal A}}\n",
    "\\newcommand{\\calB}{{\\cal B}}\n",
    "\\newcommand{\\calC}{{\\cal C}}\n",
    "\\newcommand{\\calD}{{\\cal D}}\n",
    "\\newcommand{\\calE}{{\\cal E}}\n",
    "\\newcommand{\\calF}{{\\cal F}}\n",
    "\\newcommand{\\calG}{{\\cal G}}\n",
    "\\newcommand{\\calH}{{\\cal H}}\n",
    "\\newcommand{\\calI}{{\\cal I}}\n",
    "\\newcommand{\\calJ}{{\\cal J}}\n",
    "\\newcommand{\\calK}{{\\cal K}}\n",
    "\\newcommand{\\calL}{{\\cal L}}\n",
    "\\newcommand{\\calM}{{\\cal M}}\n",
    "\\newcommand{\\calN}{{\\cal N}}\n",
    "\\newcommand{\\calO}{{\\cal O}}\n",
    "\\newcommand{\\calP}{{\\cal P}}\n",
    "\\newcommand{\\calQ}{{\\cal Q}}\n",
    "\\newcommand{\\calR}{{\\cal R}}\n",
    "\\newcommand{\\calS}{{\\cal S}}\n",
    "\\newcommand{\\calT}{{\\cal T}}\n",
    "\\newcommand{\\calU}{{\\cal U}}\n",
    "\\newcommand{\\calV}{{\\cal V}}\n",
    "\\newcommand{\\calW}{{\\cal W}}\n",
    "\\newcommand{\\calX}{{\\cal X}}\n",
    "\\newcommand{\\calY}{{\\cal Y}}\n",
    "\\newcommand{\\calZ}{{\\cal Z}}\n",
    "% Sets:\n",
    "\\newcommand{\\setA}{\\textsf{A}}\n",
    "\\newcommand{\\setB}{\\textsf{B}}\n",
    "\\newcommand{\\setC}{\\textsf{C}}\n",
    "\\newcommand{\\setD}{\\textsf{D}}\n",
    "\\newcommand{\\setE}{\\textsf{E}}\n",
    "\\newcommand{\\setF}{\\textsf{F}}\n",
    "\\newcommand{\\setG}{\\textsf{G}}\n",
    "\\newcommand{\\setH}{\\textsf{H}}\n",
    "\\newcommand{\\setI}{\\textsf{I}}\n",
    "\\newcommand{\\setJ}{\\textsf{J}}\n",
    "\\newcommand{\\setK}{\\textsf{K}}\n",
    "\\newcommand{\\setL}{\\textsf{L}}\n",
    "\\newcommand{\\setM}{\\textsf{M}}\n",
    "\\newcommand{\\setN}{\\textsf{N}}\n",
    "\\newcommand{\\setO}{\\textsf{O}}\n",
    "\\newcommand{\\setP}{\\textsf{P}}\n",
    "\\newcommand{\\setQ}{\\textsf{Q}}\n",
    "\\newcommand{\\setR}{\\textsf{R}}\n",
    "\\newcommand{\\setS}{\\textsf{S}}\n",
    "\\newcommand{\\setT}{\\textsf{T}}\n",
    "\\newcommand{\\setU}{\\textsf{U}}\n",
    "\\newcommand{\\setV}{\\textsf{V}}\n",
    "\\newcommand{\\setW}{\\textsf{W}}\n",
    "\\newcommand{\\setX}{\\textsf{X}}\n",
    "\\newcommand{\\setY}{\\textsf{Y}}\n",
    "\\newcommand{\\setZ}{\\textsf{Z}}\n",
    "% Vectors\n",
    "\\newcommand{\\bfa}{\\mathbf{a}}\n",
    "\\newcommand{\\bfb}{\\mathbf{b}}\n",
    "\\newcommand{\\bfc}{\\mathbf{c}}\n",
    "\\newcommand{\\bfd}{\\mathbf{d}}\n",
    "\\newcommand{\\bfe}{\\mathbf{e}}\n",
    "\\newcommand{\\bff}{\\mathbf{f}}\n",
    "\\newcommand{\\bfg}{\\mathbf{g}}\n",
    "\\newcommand{\\bfh}{\\mathbf{h}}\n",
    "\\newcommand{\\bfi}{\\mathbf{i}}\n",
    "\\newcommand{\\bfj}{\\mathbf{j}}\n",
    "\\newcommand{\\bfk}{\\mathbf{k}}\n",
    "\\newcommand{\\bfl}{\\mathbf{l}}\n",
    "\\newcommand{\\bfm}{\\mathbf{m}}\n",
    "\\newcommand{\\bfn}{\\mathbf{n}}\n",
    "\\newcommand{\\bfo}{\\mathbf{o}}\n",
    "\\newcommand{\\bfp}{\\mathbf{p}}\n",
    "\\newcommand{\\bfq}{\\mathbf{q}}\n",
    "\\newcommand{\\bfr}{\\mathbf{r}}\n",
    "\\newcommand{\\bfs}{\\mathbf{s}}\n",
    "\\newcommand{\\bft}{\\mathbf{t}}\n",
    "\\newcommand{\\bfu}{\\mathbf{u}}\n",
    "\\newcommand{\\bfv}{\\mathbf{v}}\n",
    "\\newcommand{\\bfw}{\\mathbf{w}}\n",
    "\\newcommand{\\bfx}{\\mathbf{x}}\n",
    "\\newcommand{\\bfy}{\\mathbf{y}}\n",
    "\\newcommand{\\bfz}{\\mathbf{z}}\n",
    "\\newcommand{\\bfalpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bfbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\bfgamma}{\\boldsymbol{\\gamma}}\n",
    "\\newcommand{\\bfdelta}{\\boldsymbol{\\delta}}\n",
    "\\newcommand{\\bfepsilon}{\\boldsymbol{\\epsilon}}\n",
    "\\newcommand{\\bfzeta}{\\boldsymbol{\\zeta}}\n",
    "\\newcommand{\\bfeta}{\\boldsymbol{\\eta}}\n",
    "\\newcommand{\\bftheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\bfiota}{\\boldsymbol{\\iota}}\n",
    "\\newcommand{\\bfkappa}{\\boldsymbol{\\kappa}}\n",
    "\\newcommand{\\bflambda}{\\boldsymbol{\\lambda}}\n",
    "\\newcommand{\\bfmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\bfnu}{\\boldsymbol{\\nu}}\n",
    "\\newcommand{\\bfomicron}{\\boldsymbol{\\omicron}}\n",
    "\\newcommand{\\bfpi}{\\boldsymbol{\\pi}}\n",
    "\\newcommand{\\bfrho}{\\boldsymbol{\\rho}}\n",
    "\\newcommand{\\bfsigma}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\bftau}{\\boldsymbol{\\tau}}\n",
    "\\newcommand{\\bfupsilon}{\\boldsymbol{\\upsilon}}\n",
    "\\newcommand{\\bfphi}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\bfchi}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\bfpsi}{\\boldsymbol{\\psi}}\n",
    "\\newcommand{\\bfomega}{\\boldsymbol{\\omega}}\n",
    "\\newcommand{\\bfxi}{\\boldsymbol{\\xi}}\n",
    "\\newcommand{\\bfell}{\\boldsymbol{\\ell}}\n",
    "% Matrices\n",
    "\\newcommand{\\bfA}{\\mathbf{A}}\n",
    "\\newcommand{\\bfB}{\\mathbf{B}}\n",
    "\\newcommand{\\bfC}{\\mathbf{C}}\n",
    "\\newcommand{\\bfD}{\\mathbf{D}}\n",
    "\\newcommand{\\bfE}{\\mathbf{E}}\n",
    "\\newcommand{\\bfF}{\\mathbf{F}}\n",
    "\\newcommand{\\bfG}{\\mathbf{G}}\n",
    "\\newcommand{\\bfH}{\\mathbf{H}}\n",
    "\\newcommand{\\bfI}{\\mathbf{I}}\n",
    "\\newcommand{\\bfJ}{\\mathbf{J}}\n",
    "\\newcommand{\\bfK}{\\mathbf{K}}\n",
    "\\newcommand{\\bfL}{\\mathbf{L}}\n",
    "\\newcommand{\\bfM}{\\mathbf{M}}\n",
    "\\newcommand{\\bfN}{\\mathbf{N}}\n",
    "\\newcommand{\\bfO}{\\mathbf{O}}\n",
    "\\newcommand{\\bfP}{\\mathbf{P}}\n",
    "\\newcommand{\\bfQ}{\\mathbf{Q}}\n",
    "\\newcommand{\\bfR}{\\mathbf{R}}\n",
    "\\newcommand{\\bfS}{\\mathbf{S}}\n",
    "\\newcommand{\\bfT}{\\mathbf{T}}\n",
    "\\newcommand{\\bfU}{\\mathbf{U}}\n",
    "\\newcommand{\\bfV}{\\mathbf{V}}\n",
    "\\newcommand{\\bfW}{\\mathbf{W}}\n",
    "\\newcommand{\\bfX}{\\mathbf{X}}\n",
    "\\newcommand{\\bfY}{\\mathbf{Y}}\n",
    "\\newcommand{\\bfZ}{\\mathbf{Z}}\n",
    "% bf greek symbols\n",
    "\\newcommand{\\bfGamma}{\\boldsymbol{\\Gamma}}\n",
    "\\newcommand{\\bfDelta}{\\boldsymbol{\\Delta}}\n",
    "\\newcommand{\\bfTheta}{\\boldsymbol{\\Theta}}\n",
    "\\newcommand{\\bfLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\bfPi}{\\boldsymbol{\\Pi}}\n",
    "\\newcommand{\\bfSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\bfUpsilon}{\\boldsymbol{\\Upsilon}}\n",
    "\\newcommand{\\bfPhi}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\bfPsi}{\\boldsymbol{\\Psi}}\n",
    "\\newcommand{\\bfOmega}{\\boldsymbol{\\Omega}}\n",
    "% Blackboard Bold:\n",
    "\\newcommand{\\bbA}{\\mathbb{A}}\n",
    "\\newcommand{\\bbB}{\\mathbb{B}}\n",
    "\\newcommand{\\bbC}{\\mathbb{C}}\n",
    "\\newcommand{\\bbD}{\\mathbb{D}}\n",
    "\\newcommand{\\bbE}{\\mathbb{E}}\n",
    "\\newcommand{\\bbF}{\\mathbb{F}}\n",
    "\\newcommand{\\bbG}{\\mathbb{G}}\n",
    "\\newcommand{\\bbH}{\\mathbb{H}}\n",
    "\\newcommand{\\bbI}{\\mathbb{I}}\n",
    "\\newcommand{\\bbJ}{\\mathbb{J}}\n",
    "\\newcommand{\\bbK}{\\mathbb{K}}\n",
    "\\newcommand{\\bbL}{\\mathbb{L}}\n",
    "\\newcommand{\\bbM}{\\mathbb{M}}\n",
    "\\newcommand{\\bbN}{\\mathbb{N}}\n",
    "\\newcommand{\\bbO}{\\mathbb{O}}\n",
    "\\newcommand{\\bbP}{\\mathbb{P}}\n",
    "\\newcommand{\\bbQ}{\\mathbb{Q}}\n",
    "\\newcommand{\\bbR}{\\mathbb{R}}\n",
    "\\newcommand{\\bbS}{\\mathbb{S}}\n",
    "\\newcommand{\\bbT}{\\mathbb{T}}\n",
    "\\newcommand{\\bbU}{\\mathbb{U}}\n",
    "\\newcommand{\\bbV}{\\mathbb{V}}\n",
    "\\newcommand{\\bbW}{\\mathbb{W}}\n",
    "\\newcommand{\\bbX}{\\mathbb{X}}\n",
    "\\newcommand{\\bbY}{\\mathbb{Y}}\n",
    "\\newcommand{\\bbZ}{\\mathbb{Z}}\n",
    "$$\n",
    "\n",
    "$\\bfA$, $\\bfB$, $\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /home/vdhiman/.local/venvs/book490/lib/python3.10/site-packages (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /home/vdhiman/.local/venvs/book490/lib/python3.10/site-packages (from scipy) (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NTkGmFniOLXZ"
   },
   "outputs": [],
   "source": [
    "import scipy.signal as ss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VidZ_XGXORLI"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 3, 5],\n",
    "               [2, 7, 9],\n",
    "               [11, 13, 17]], dtype='f8')\n",
    "W = np.array([[19, 23],\n",
    "              [29, 31]], dtype='f8')\n",
    "# X = np.ones(12, dtype='f8').reshape(3,4) + 1\n",
    "# W = np.ones(6, dtype='f8').reshape(2,3) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qc4jF-jBgUXn"
   },
   "source": [
    "$\\newcommand{\\bbR}{\\mathbb{R}}$\n",
    "A 2D convolution operation between the finite dimensional kernel weights $W \\in \\bbR^{K \\times L}$ and image $X\\in\\bbR^{I \\times J}$ is denoted as $Y = X * W\\in \\bbR^{I-K+1,J-L+1}$. Let the convolution kernel be smaller than the image in both the dimensions, $K < I$ and $L<J$.\n",
    "Then the 2D convolution operation for all $i \\in \\{1, \\dots, I-K+1\\}, j\\in \\{1, \\dots, J-K+1\\}$ is  defined as,\n",
    "\\begin{align}\n",
    "Y &= W * X\\\\\n",
    " Y_{i,j} &= \\sum_{k=1}^K \\sum_{l=1}^L W_{k,l} X_{i+K-k,j+L-l} \\\\\n",
    " &= \\sum_{p=i}^{K+i-1} \\sum_{q=j}^{L+j-1} X_{p, q} W_{i+K-p,j+L-q}\n",
    "\\end{align}\n",
    "The two expressions are equivalent and can obtained by variable substitution of $p=i+K-k$ and $q=j+L-l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JY96TG2mOSiJ",
    "outputId": "28520a1b-6724-43dd-e6bf-c78f7f6eebf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 297.,  570.,  362.],\n",
       "        [ 765., 1100.,  670.],\n",
       "        [ 718.,  896.,  527.]]),\n",
       " np.float64(363.0),\n",
       " np.float64(297.0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_padding(padding):\n",
    "  if padding is None:\n",
    "    padding = [(0, s-1) for s in W.shape]\n",
    "  return padding\n",
    "def t_convolve2d(X, W, padding=None):\n",
    "  padding = handle_padding(padding)\n",
    "  Xpadded = np.pad(X, padding)\n",
    "  Y = ss.convolve2d(Xpadded, W, mode='valid')\n",
    "  return Y\n",
    "\n",
    "Y = t_convolve2d(X, W)\n",
    "Y, (X[:2, :2] * W).sum(), (X[:2, :2] * W[::-1, ::-1]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbnfvJmagck9"
   },
   "source": [
    "## Finding vector jacobian product\n",
    "$\\newcommand{\\p }{\\partial}$\n",
    "$\\newcommand{\\pfrac}[2]{\\frac{\\p {#1}}{\\p {#2}}}$\n",
    "Let the eventual loss function be $l(Y)$ and we are given the backpropagated gradient $\\pfrac{l}{Y}$. We want to find the vector jacobian products, $\\pfrac{l}{X}$ and $\\pfrac{l}{W}$.\n",
    "\n",
    "\\begin{align}\n",
    "\\pfrac{}{W} l(Y) &= \\sum_{i=1}^{I-K+1} \\sum_{j=1}^{J-L+1} \\pfrac{l}{Y_{i,j}} \\pfrac{Y_{i,j}}{W}\\\\\n",
    "\\pfrac{}{X} l(Y) &= \\sum_{i=1}^{I-K+1} \\sum_{j=1}^{J-L+1} \\pfrac{l}{Y_{i,j}} \\pfrac{Y_{i,j}}{X}\n",
    "\\end{align}\n",
    "\n",
    "### Finding $\\pfrac{l}{W}$\n",
    "Our main task is to find $\\pfrac{Y_{i,j}}{W}$. Let's find the $(k,l)$th element of this derivative,\n",
    "\n",
    "\\begin{align}\n",
    "\\pfrac{Y_{i,j}}{W_{k,l}}= \\pfrac{}{W_{k,l}} \\sum_{k=1}^K \\sum_{l=1}^L W_{k,l} X_{i+K-k,j+L-l} &=\n",
    "X_{i+K-k,j+L-l} &\\text{ for all} i \\le I, k \\le K, j \\le J, l \\le L\n",
    "\\end{align}\n",
    "\n",
    "That was easy. Let's put it back in the equation one above to find $\\pfrac{l}{W_{k,l}}$\n",
    "\\begin{align}\n",
    "\\pfrac{}{W_{k,l}} l(Y) &= \\sum_{i=1}^{I-K+1} \\sum_{j=1}^{J-L+1} \\pfrac{l}{Y_{i,j}}X_{i+K-k,j+L-l}.\n",
    "\\end{align}\n",
    "\n",
    "$\\newcommand{\\calM}{\\mathcal{M}}$\n",
    "Define mirroring operator of an image $Z \\in \\bbR^{I \\times J}$ as $\\calM(Z)$ as,\n",
    "\\begin{align}\n",
    "\\calM(Z)_{i,j} &= Z_{I+1-i,J+1-j}\n",
    "\\end{align}\n",
    "Rewrite $\\pfrac{l}{W_{k,l}}$ in terms of mirrored $\\calM(\\pfrac{l}{W})_{m,n}$,\n",
    "\\begin{align}\n",
    "\\calM\\left(\\pfrac{}{W} l(Y)\\right)_{m,n}\n",
    "&= \\sum_{i=1}^{I-K+1} \\sum_{j=1}^{J-L+1} \\pfrac{l}{Y_{i,j}}X_{i+K-(K+1-m),j+L-(L+1-n)}\\\\\n",
    "&= \\sum_{i=1}^{I-K+1} \\sum_{j=1}^{J-L+1} \\pfrac{l}{Y_{i,j}}X_{m-1+i,n-1+j}\\\\\n",
    "\\end{align}\n",
    "Change the indexing variables $p=I-K+2-i$ and $q=J-L+2-j$,\n",
    "\\begin{align}\n",
    "\\calM\\left(\\pfrac{}{W} l(Y)\\right)_{m,n}\n",
    " &= \\sum_{p=1}^{I-K+1} \\sum_{q=1}^{J-L+1} \\calM\\left(\\pfrac{l}{Y}\\right)_{p,q} X_{m+I-K+1-p,n+J-L+1-n}.\n",
    "\\end{align}\n",
    "Left hand side of the above equation is a convolution operation, with $\\pfrac{l}{Y}$ as the kernel,\n",
    "\\begin{align}\n",
    "\\calM\\left(\\pfrac{}{W} l(Y)\\right) &=  \\calM(\\pfrac{l}{Y}) * X\\\\\n",
    "\\implies \\pfrac{}{W} l(Y) &= \\calM\\left( \\calM(\\pfrac{l}{Y}) * X \\right)\n",
    "\\end{align}\n",
    "\n",
    "It turns out the following is equivalent,\n",
    "\\begin{align}\n",
    "\\pfrac{}{W} l(Y) &= \\pfrac{l}{Y} * \\calM(X)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siQ3ph2tS3jJ"
   },
   "source": [
    "### Finding $\\pfrac{l}{X}$\n",
    "Let's try to do the same with $\\pfrac{l}{X}$ by finding $\\pfrac{Y_{i,j}}{X_{p,q}}$ first,\n",
    "\\begin{align}\n",
    "\\pfrac{Y_{i,j}}{X_{p,q}} &= \\pfrac{}{X_{p,q}} \\sum_{p=i}^{K+i-1} \\sum_{q=j}^{L+j-1} X_{p, q} W_{i+K-p,j+L-q}\\\\\n",
    "&= \\begin{cases}\n",
    "W_{i+K-p,j+L-q} & \\text{ if } 1 \\le i+K-p \\le K \\text { and } 1 \\le j+L-q \\le J\\\\\n",
    "0 & \\text{ otherwise }\n",
    "\\end{cases}.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Using this we can find the $(p,q)$th element of $\\pfrac{l}{X}$ as,\n",
    "\\begin{align}\n",
    "\\pfrac{}{X_{p,q}} l(Y) &= \\sum_{i=1}^{I-K+1} \\sum_{j=1}^{J-L+1} \\pfrac{l}{Y_{i,j}} \\pfrac{Y_{i,j}}{X_{p,q}}\\\\\n",
    "&= \\sum_{i=1}^{p-K} \\sum_{j=1}^{p-L} \\pfrac{l}{Y_{i,j}} . 0\n",
    "+ \\sum_{i=p-K+1}^{p} \\sum_{j=q-L+1}^{q} \\pfrac{l}{Y_{i,j}}  W_{i+K-p,j+L-q}\\\\\n",
    "&\\qquad + \\sum_{i=p+1}^{I-K+1} \\sum_{j=q+1}^{J-L+1} \\pfrac{l}{Y_{i,j}} . 0\\\\\n",
    "&= \\sum_{i=p-K+1}^{p} \\sum_{j=q-L+1}^{q} \\pfrac{l}{Y_{i,j}}  W_{i+K-p,j+L-q}.\n",
    "\\end{align}\n",
    "In the last step we reduced the scope  of summation where $\\pfrac{Y_{i,j}}{X_{p,q}}$ is non-zero. However, due to the change of variables, some of the indexing on $\\pfrac{l}{Y_{i,j}}$ is invalid. To remedy that define a padded gradient $G \\in \\bbR^{I+K-1 \\times J+L-1}$ that is defined as,\n",
    "\\begin{align}\n",
    "G_{m, n} &= \\begin{cases}\n",
    "0 & \\text{ if } n \\le K-1 \\text{ or } m \\le L-1 \\\\\n",
    "\\pfrac{l}{Y_{m-K+1,n-L+1}} & \\text{ if } K \\le m \\le I \\text{ and } L \\le n \\le J\\\\\n",
    "0 & \\text{ if } I+1 \\le n \\le I+K-1 \\text{ or } J+1 \\le m \\le J+L-1 \\\\\n",
    "\\end{cases}\\\\\n",
    "\\implies \\pfrac{l}{Y_{i,j}} &= G_{i+K-1,j+L-1}\n",
    "\\end{align}\n",
    "Put this back into $\\pfrac{l}{X_{p,q}}$,\n",
    "\\begin{align}\n",
    "\\pfrac{}{X_{p,q}} l(Y)\n",
    "&= \\sum_{i=p-K+1}^{p} \\sum_{j=q-L+1}^{q} G_{i+K-1,j+L-1}  W_{i+K-p,j+L-q}.\n",
    "\\end{align}\n",
    "Let us do a change of variable to write the above sum in terms of $W$ indices $k = i+K-p$ or $i=p-K+k$. Similarly, $l = j+L-q$ or $j=q-L+l$. This leads to,\n",
    "\\begin{align}\n",
    "\\pfrac{}{X_{p,q}} l(Y) &= \\sum_{k=1}^{K} \\sum_{l=1}^{L}  W_{k,l}G_{p+k-1,q+l-1}\n",
    "\\end{align}\n",
    "The above is almost a convolution except that the $k$ and $l$ indices appear with a positive sign. To remedy that we use the mirror operator of $W$,\n",
    "\\begin{align}\n",
    "\\calM(W)_{k,l} &= W_{K+1-k,L+1-l} \\text{ for all } k \\in \\{1, \\dots, K\\}, i \\in \\{ 1, \\dots, L\\}\n",
    "\\end{align}\n",
    "Use this to write $\\pfrac{l}{X_{p,q}}$ in terms of $\\calM(G)$,\n",
    "\\begin{align}\n",
    "\\pfrac{}{X_{p,q}} l(Y) &= \\sum_{k=1}^{K} \\sum_{l=1}^{L}  \\calM(W)_{K+1-k,L+1-l} G_{p+k-1,q+l-1}\\\\\n",
    "&= \\sum_{m=1}^{K} \\sum_{n=1}^{L}  \\calM(W)_{m,n} G_{p+K-m,q+L-n}\n",
    "\\end{align}\n",
    "\n",
    "The  right hand side the convolution oeprator,\n",
    "\\begin{align}\n",
    "\\pfrac{}{X} l(Y) &= G * \\calM(W)\n",
    "\\end{align}\n",
    "\n",
    "Equivalently,\n",
    "\\begin{align}\n",
    "\\implies \\pfrac{}{X} l(Y) &= \\calM\\left( \\calM(G) * X \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CEBeX6K0Om_9"
   },
   "outputs": [],
   "source": [
    "def unpad(X, padding):\n",
    "  return X[tuple(slice(s, -e) for s, e in padding)]\n",
    "\n",
    "def mirror(X):\n",
    "  return X[::-1, ::-1]\n",
    "\n",
    "def convolve2d_vjp(X, W, dl__dY, padding=None):\n",
    "  padding = handle_padding(padding)\n",
    "  Xpadded = np.pad(X, padding)\n",
    "\n",
    "  # Additional zero padding\n",
    "  b_padding = [(s-1, s-1)  for s in W.shape]\n",
    "  # The default padding needs to be reversed for dl__dY\n",
    "  dl__dY_bpadded = np.pad(dl__dY, b_padding)\n",
    "\n",
    "  dl__dW = ss.convolve2d(dl__dY, mirror(Xpadded), mode='valid')\n",
    "  assert dl__dW.shape == W.shape\n",
    "\n",
    "  # use the valid convolutions with custom padded X and W\n",
    "  dl__dXp = ss.convolve2d(dl__dY_bpadded, mirror(W), mode='valid')\n",
    "  assert dl__dXp.shape == Xpadded.shape\n",
    "  dl__dX = unpad(dl__dXp, padding)\n",
    "\n",
    "  return (dl__dX, dl__dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-d5dHJq6Onhg",
    "outputId": "6af95e31-4ecb-4666-be36-c177215b4889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 30.97966328,  60.02665032,  60.02665032],\n",
       "        [ 54.00124792, 101.8634066 , 101.97709344],\n",
       "        [ 53.88756108, 101.8634066 , 101.8634066 ]]),\n",
       " array([[45.98632586, 58.94662536],\n",
       "        [54.17177817, 67.87104212]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numerical_convolve2d_vjp(X, W, dl__dY, h=1e-12, **kw):\n",
    "  # We are going to perturb each pixel of X by a small amount h\n",
    "  # and observe the corresponding change in Y\n",
    "  dl__dX = np.empty_like(X)\n",
    "  Y = t_convolve2d(X, W, **kw) # Y before any perturbation\n",
    "  for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "      Xp = X.copy()\n",
    "      Xp[i, j] += h # perturbed image at pixel (i,j)\n",
    "      Yp = t_convolve2d(Xp, W, **kw) # convolution result when perturbed\n",
    "      # numerical derivative of image Y with respect to pixel X[i,j]\n",
    "      dY__dXij = (Yp - Y) / h\n",
    "      # numerical derivative of loss l with respect to pixel X[i,j]\n",
    "      dl__dX[i, j] = (dl__dY * dY__dXij).sum()\n",
    "\n",
    "  dl__dW = np.empty_like(W)\n",
    "  for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[1]):\n",
    "      Wp = W.copy()\n",
    "      Wp[i, j] += h # perturbed kernel at pixel (i,j)\n",
    "      Yp = t_convolve2d(X, Wp, **kw) # convolution result when perturbed\n",
    "      # numerical derivative of image Y with respect to pixel X[i,j]\n",
    "      dY__dWij = (Yp - Y) / h\n",
    "      # numerical derivative of loss l with respect to pixel X[i,j]\n",
    "      dl__dW[i, j] = (dl__dY * dY__dWij).sum()\n",
    "\n",
    "  return dl__dX, dl__dW\n",
    "\n",
    "random_dl__dY = np.ones(Y.shape)\n",
    "nvjp_X, nvjp_W =numerical_convolve2d_vjp(X, W, random_dl__dY)\n",
    "nvjp_X, nvjp_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyEXtLAHSFKB",
    "outputId": "54afd40e-0814-49b0-852b-2cc8745203b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 31.,  60.,  60.],\n",
       "        [ 54., 102., 102.],\n",
       "        [ 54., 102., 102.]]),\n",
       " array([[46., 59.],\n",
       "        [54., 68.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vjp_X, vjp_W = convolve2d_vjp(X, W, random_dl__dY)\n",
    "vjp_X, vjp_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EPxf-J3w5q2u"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(nvjp_X, nvjp_X, atol=1e-1, rtol=1e-2)\n",
    "assert np.allclose(nvjp_W, nvjp_W, atol=1e-1, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wev22BiPSTrT",
    "outputId": "4707eda3-6d97-4103-e652-53efe7d7ea70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actually try a random one\n",
    "random_dl__dY = np.random.rand(*Y.shape)\n",
    "all([\n",
    "    np.allclose(nvjp, cvjp, atol=1e-1, rtol=1e-2)\n",
    "    for nvjp, cvjp in zip(\n",
    "        numerical_convolve2d_vjp(X, W, random_dl__dY),\n",
    "        convolve2d_vjp(X, W, random_dl__dY))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86JiitfudkUL",
    "outputId": "a0bf45e9-08c6-4fa5-9863-66f3ef15dde1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All random values\n",
    "X = np.random.rand(3,4)\n",
    "W = np.random.rand(2,2)\n",
    "Y = t_convolve2d(X, W)\n",
    "random_dl__dY = np.random.rand(*Y.shape)\n",
    "all([\n",
    "    np.allclose(nvjp, cvjp, rtol=1e-2)\n",
    "    for nvjp, cvjp in zip(\n",
    "        numerical_convolve2d_vjp(X, W, random_dl__dY),\n",
    "        convolve2d_vjp(X, W, random_dl__dY))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "o7P8vcd-d0NN"
   },
   "outputs": [],
   "source": [
    "def test_convolve2d_vjp():\n",
    "    # With random shapes\n",
    "    W_shape = np.random.randint(1, 9, size=(2,))\n",
    "    maxW = max(W_shape)\n",
    "    X_shape = np.random.randint(maxW, 40, size=(2,))\n",
    "    # All random values\n",
    "    X = np.random.rand(*X_shape)\n",
    "    W = np.random.rand(*W_shape)\n",
    "    Y = t_convolve2d(X, W)\n",
    "    random_dl__dY = np.random.rand(*Y.shape)\n",
    "    return all([\n",
    "    np.allclose(nvjp, cvjp, rtol=1e-2, atol=1e-3)\n",
    "        for nvjp, cvjp in zip(\n",
    "            numerical_convolve2d_vjp(X, W, random_dl__dY),\n",
    "            convolve2d_vjp(X, W, random_dl__dY))\n",
    "        ])\n",
    "assert test_convolve2d_vjp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mKivfmYohwzw"
   },
   "outputs": [],
   "source": [
    "# Run the test a hundred times just to make sure\n",
    "for _ in range(100):\n",
    "  assert test_convolve2d_vjp()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
